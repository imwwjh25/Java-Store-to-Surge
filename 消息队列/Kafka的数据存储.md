Kafka 的数据存储核心围绕「高效持久化、高吞吐读写、顺序访问」设计，底层采用 **磁盘文件 + 内存索引** 的组合结构，配合关键数据结构优化路由和查询效率，核心存储相关数据结构及原理如下：

## 一、核心存储架构：日志文件（Log）+ 索引文件（Index）

Kafka 的核心存储单元是 **分区（Partition）**，每个分区对应一套「日志文件 + 索引文件」，数据按「顺序写入、顺序读取」组织（类似日志系统），这是 Kafka 高吞吐的核心基础。

### 1. 日志文件（.log）：存储原始消息

- **数据结构本质**：**顺序写入的追加日志（Append-Only Log）**（逻辑上是线性有序的消息序列，物理上存储为多个分段文件）；

- 存储内容 ：

    - 每条消息包含：消息体（value）、消息键（key）、时间戳、偏移量（offset，分区内唯一递增标识）、压缩类型等元数据；
    - 物理存储：为避免单个文件过大，日志文件会按「大小阈值（默认 1GB）」或「时间阈值」分割为多个 **分段文件（Segment）**，命名格式为 `[baseOffset].log`（baseOffset 是该分段的起始消息偏移量）；

- 核心特性 ：

    - 顺序写入：消息只能追加到当前分段的末尾，不支持随机修改（磁盘顺序 IO 效率远高于随机 IO，是高吞吐的关键）；
    - 过期清理：按「日志保留策略」（时间 / 大小 / 日志清理策略）删除旧分段文件，释放磁盘空间。

### 2. 索引文件（.index + .timeindex）：加速消息查询

Kafka 为每个日志分段（.log）配套两个索引文件，用于快速定位消息在日志文件中的物理位置，避免全文件扫描：

#### （1）偏移量索引（.index）：按 offset 快速查找

- **数据结构**：**稀疏索引（Sparse Index）**（本质是「有序键值对的数组」，按 offset 升序排列）；

- 存储内容 ：

    - 键（Key）：消息的偏移量（offset）；
    - 值（Value）：该消息在对应 `.log` 文件中的「物理偏移量（文件内字节位置）」；

- 工作原理 ：

    - 写入时：每间隔一定数量的消息（默认 4KB 触发一次），记录一条索引项（并非每条消息都有索引，稀疏索引平衡空间和查询效率）；
    - 查询时：根据目标 offset，通过「二分查找」在索引文件中找到「小于等于目标 offset 的最大索引项」，再从该索引项对应的物理位置开始，在 `.log` 文件中顺序扫描少量消息，即可找到目标消息（查询效率 O (log n)）；

- **示例**：若要查询 offset=1000 的消息，先二分查找 `.index` 文件，找到 baseOffset ≤ 1000 的最大索引项（如 baseOffset=990，物理位置 = 12345），再从 `.log` 文件的 12345 字节处开始扫描，直到找到 offset=1000 的消息。

#### （2）时间戳索引（.timeindex）：按时间戳快速查找

- **数据结构**：同样是「稀疏索引数组」，按时间戳升序排列；

- 存储内容 ：

    - 键（Key）：消息的时间戳；
    - 值（Value）：对应的消息 offset + 在 `.log` 文件中的物理偏移量；

- **作用**：支持按时间范围查询消息（如消费近 1 小时的消息），避免全量扫描日志文件，底层通过二分查找时间戳索引定位起始 offset。

## 二、其他核心数据结构（支撑集群 / 路由 / 元数据）

除了分区的日志和索引，Kafka 还依赖以下数据结构支撑集群运行：

### 1. 主题 - 分区映射：哈希表（Hash Table）

- **应用场景**：Kafka 集群的元数据（如 Topic 包含哪些 Partition、每个 Partition 的 Leader/Follower 副本分布在哪些 Broker）存储在 ZooKeeper 中，本地缓存时采用哈希表；

- 存储内容 ：

    - 键（Key）：`TopicName + PartitionId`（如 `order-topic-0`）；
    - 值（Value）：Partition 的元数据（Leader Broker ID、Follower 列表、ISR 集合等）；

- **优势**：查询 Partition 元数据时效率 O (1)，支撑高并发的生产 / 消费请求路由。

### 2. 消费组偏移量存储：哈希表 + 日志

- **应用场景**：记录每个消费组（Consumer Group）对每个 Partition 的消费进度（即已消费的最大 offset）；

- 存储方式 ：

    - 旧版本：存储在 ZooKeeper 的哈希节点中（键：`/consumers/{group-id}/offsets/{topic}/{partition}`，值：offset）；
    - 新版本：存储在 Kafka 内置的 `__consumer_offsets` 主题中（该主题是普通 Topic，消息键为 `group-id + topic + partition`，值为 offset，底层同样是「日志 + 索引」结构）；

- **优势**：内置 Topic 存储支持高吞吐、高可用，避免 ZooKeeper 成为瓶颈。

### 3. 分区副本同步：环形队列（Circular Queue）

- **应用场景**：Leader 副本与 Follower 副本的同步（日志复制）；
- **工作原理**：Leader 副本将接收的消息写入本地日志的同时，放入一个环形队列（缓冲区），Follower 副本通过拉取（Pull）方式从队列中获取消息并同步到本地；
- **优势**：环形队列支持批量读写，减少副本同步的 IO 开销，且能平衡生产速率和同步速率（避免 Leader 被 Follower 拖慢）。

### 4. 消息压缩：字典（Dictionary）+ 变长编码（Varint）

- **应用场景**：Kafka 支持消息压缩（Gzip、Snappy、LZ4 等），减少网络传输和磁盘存储开销；

- 核心数据结构 ：

    - 字典：压缩时构建重复消息的字典映射（如重复的消息键、元数据），用字典索引替代重复内容；
    - Varint 编码：对消息长度、offset 等整数类型进行变长编码（小数值占用更少字节）；

- **优势**：压缩率高，且解压时无需全量解压，支持流式解压（不影响消费效率）。

## 三、关键设计亮点（为什么这样设计？）

1. **顺序写入日志**：磁盘顺序 IO 速度接近内存，远高于随机 IO，支撑 Kafka 每秒百万级消息写入；
2. **稀疏索引**：平衡索引空间和查询效率（若为每条消息建索引，索引文件会过大；无索引则查询低效）；
3. **分段日志**：避免单个文件过大，便于日志清理（直接删除旧分段）、副本同步（按分段批量同步）；
4. **哈希表元数据缓存**：集群路由、消费组 offset 查询均为 O (1) 效率，支撑高并发。

## 四、面试延伸考点

### 1. Kafka 为什么不用 B+ 树存储消息？

- B+ 树适合随机查询和范围查询，但 Kafka 的核心场景是「顺序生产、顺序消费」，无需随机修改消息；
- 顺序日志的写入效率（O (1)）远高于 B+ 树的插入效率（O (log n)），更适配高吞吐场景；
- 日志 + 稀疏索引的组合，已能满足「按 offset / 时间戳查询」的需求，且实现更简单、开销更低。

### 2. 分段日志的好处是什么？

- 便于日志清理：直接删除过期的分段文件（如保留 7 天的日志，删除 7 天前的分段），无需修改现有文件；
- 提升读写性能：单个分段文件大小可控（默认 1GB），避免大文件的 IO 开销；
- 支持并行操作：不同分段可并行被读取（如消费组同时消费一个分区的多个分段），提升吞吐量。

### 3. 偏移量索引为什么是稀疏的？

- 若为每条消息建索引，索引文件大小会接近日志文件大小（空间开销翻倍）；
- 稀疏索引仅需间隔存储索引项（如每 4KB 一条），空间开销极小，且查询时仅需少量顺序扫描（日志文件是顺序存储的，扫描效率高），平衡了空间和时间成本。

## 总结

Kafka 的存储数据结构设计完全围绕「高吞吐、高可用、低延迟」核心目标：

- 核心存储：**日志文件（顺序写入）+ 稀疏索引（快速查询）**，适配消息的生产消费模式；
- 支撑结构：哈希表（元数据路由）、环形队列（副本同步）、压缩编码（空间优化），保障集群高效运行；
- 本质：用最简单的「日志 + 索引」组合，最大化发挥磁盘顺序 IO 的优势，避免复杂数据结构的开销。