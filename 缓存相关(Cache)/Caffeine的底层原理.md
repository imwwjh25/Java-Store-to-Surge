Caffeine 是基于 **Java 8+** 的高性能本地缓存库，底层核心是结合了 **LRU（最近最少使用）、LFU（最不经常使用）和时间衰减** 的混合淘汰策略（W-TinyLFU），并通过无锁并发设计、预计算等优化，实现了接近理论极限的读写性能。

### 一、核心淘汰策略：W-TinyLFU（解决传统策略的痛点）



传统缓存淘汰策略（如纯 LRU、纯 LFU）存在明显缺陷：

- **纯 LRU**：无法识别 “突发访问”（如某冷数据突然被大量访问，却因历史访问少被淘汰）；
- **纯 LFU**：无法淘汰 “历史高频但当前不再访问” 的 “僵尸数据”（如某数据过去访问多，现在无人访问，却长期占用缓存）。

Caffeine 采用 **W-TinyLFU** 策略，融合两者优势，具体分为三层：

#### 1. 第一层：Window Cache（窗口缓存）



- **作用**：临时存储 “近期新访问” 的数据，过滤 “突发的一次性访问”（防止冷数据冲击缓存）。

- 逻辑

  ：

  - 窗口缓存是一个小型的 LRU 结构（默认占总缓存的 1%）；
  - 数据首次访问时先进入窗口缓存，只有在 **窗口内被再次访问**（证明不是一次性访问），才会被晋升到主缓存；
  - 窗口缓存满时，按 LRU 淘汰 “仅访问一次” 的临时数据。

#### 2. 第二层：Main Cache（主缓存）



- 作用

  ：存储 “长期有效” 的高频数据，分为

  Protected（受保护区）

  和

  Probation（ probation 区）

  两部分：

  - **Protected 区**：占主缓存的 80%，存储 “近期高频访问” 的数据（LFU 策略，按访问次数排序，不轻易淘汰）；
  - **Probation 区**：占主缓存的 20%，存储 “访问频率下降” 的数据（LRU 策略，作为淘汰候选）。

- 晋升 / 淘汰逻辑

  ：

  - 窗口缓存中被再次访问的数据，进入 Probation 区；
  - 若 Probation 区的数据被再次访问（频率提升），则晋升到 Protected 区；
  - 主缓存满时，先淘汰 Probation 区的 LRU 数据；若 Probation 区空，则淘汰 Protected 区中访问频率最低的数据。

#### 3. 第三层：Frequency Sketch（频率估算器）



- **作用**：高效统计数据的访问频率（避免为每个数据存储精确计数器，节省内存）。

- 实现

  ：基于

  Count-Min Sketch

  算法（一种概率性数据结构）：

  - 用多个哈希函数将数据映射到一个小型数组的不同位置，每个位置存储 “近似访问次数”；
  - 统计时取多个哈希位置的最小值作为 “估算频率”，既减少内存占用（无需为每个 key 存计数器），又能抵抗哈希冲突导致的统计偏差。

### 二、无锁并发设计（保障高并发性能）



Caffeine 是并发安全的缓存库，底层通过 **分段锁（Striped Lock）+ CAS 操作** 实现无锁 / 低锁并发，避免传统全局锁的性能瓶颈：

#### 1. 缓存分段（Segment）



- 将缓存的 key 按哈希值分成多个 “分段（Segment）”，每个分段对应一个独立的锁（或无锁结构）；
- 不同分段的读写操作可并行执行，仅同一分段的操作需竞争锁，大幅提升并发吞吐量。

#### 2. 无锁数据结构（Node 节点）



- 缓存的底层存储（如窗口缓存、主缓存）基于 **链表 / 数组** 实现，每个 Node 节点的状态（如访问次数、过期时间）通过 **volatile 修饰** 保证可见性；
- 对节点的修改（如晋升、淘汰）优先使用 **CAS 原子操作**（避免加锁），仅在复杂操作（如节点迁移）时才使用分段锁，进一步降低锁开销。

### 三、时间衰减与过期策略（精准控制缓存生命周期）



Caffeine 支持 **过期时间（Expire）** 和 **最大存活时间（Max Age）**，底层通过两种机制实现高效过期管理：

#### 1. 惰性过期（Lazy Expiration）



- **触发时机**：当访问某个 key 时，先检查是否过期，若过期则立即淘汰并返回 null；
- **优势**：无需额外线程，无定时任务开销；
- **不足**：“冷过期数据”（长期不被访问）会占用内存，直到被主动访问才会淘汰。

#### 2. 定时清理（Scheduled Cleanup）



- **触发时机**：Caffeine 启动一个 **守护线程（ExpirationScheduler）**，定期（默认 1 秒）扫描 “可能过期” 的分段，批量淘汰过期数据；
- **优化**：线程仅扫描 “有过期数据的分段”（通过标记位过滤），避免全量扫描的性能损耗；
- **作用**：补充惰性过期，及时清理 “冷过期数据”，释放内存。

### 四、预计算与内存优化（降低读写延迟）



1. 预计算哈希值

   ：

   - 首次插入 key 时，提前计算并存储 key 的哈希值（避免每次查询时重复计算），减少 CPU 开销。

2. 紧凑的内存布局

   ：

   - 缓存节点（Node）采用 **字段紧凑排列**（如用 int 存储访问次数、用 long 存储过期时间），减少对象头和内存对齐带来的内存浪费；
   - 对 “小 value”（如 Integer、String）采用 **值传递** 而非引用传递，避免对象包装的内存开销。

### 五、核心优势总结（为什么 Caffeine 性能高）



| 设计点            | 解决的问题          | 带来的优势                  |
| ----------------- | ------------------- | --------------------------- |
| W-TinyLFU 策略    | 传统 LRU/LFU 的缺陷 | 命中率接近理论最优          |
| 分段锁 + CAS      | 全局锁的并发瓶颈    | 高并发下读写性能无明显下降  |
| 惰性 + 定时过期   | 过期数据的内存占用  | 低开销且及时释放内存        |
| 预计算 + 紧凑布局 | 重复计算与内存浪费  | 降低 CPU / 内存开销，延迟低 |

### 总结



Caffeine 的底层本质是：**用 “智能淘汰策略（W-TinyLFU）” 保证高命中率，用 “无锁并发” 保证高吞吐量，用 “精准过期” 控制内存，最终实现 “高性能、高命中率、低开销” 的本地缓存**。这也是它成为 Spring Boot 2.x 默认缓存、替代 Guava Cache 的核心原因。
