### 1. 分页查询参数 + 深分页问题优化

#### 一、分页查询核心参数

分页查询的核心是「定位数据范围」，常见参数组合有 2 种（适配不同场景）：

| 参数组合                                  | 说明                                                         | 适用场景                          | 示例 SQL（MySQL）                                            |
| ----------------------------------------- | ------------------------------------------------------------ | --------------------------------- | ------------------------------------------------------------ |
| `pageNum`（页码）+ `pageSize`（每页条数） | 经典分页，用户输入页码和每页显示数，后端计算偏移量 `offset = (pageNum-1)*pageSize` | 前端分页控件（如列表分页）        | `SELECT * FROM t_user LIMIT 100000, 20`（查询第 5001 页，每页 20 条） |
| `lastId`（上一页最后一条 ID）+ `pageSize` | 游标分页（滚动分页），以上一页末尾 ID 为锚点，查询后续数据   | 无限滚动列表（如朋友圈、Feed 流） | `SELECT * FROM t_user WHERE id > 100000 LIMIT 20`（查询 ID>100000 的 20 条数据） |

- 补充参数：`sortField`（排序字段）、`sortOrder`（排序方向），确保分页结果有序（默认按主键升序）。

#### 二、深分页问题（页数过大，如几万页）的核心痛点

当 `pageNum` 极大时（如 `pageNum=10000`，`pageSize=20`），`LIMIT offset, pageSize` 会出现性能暴跌：

- 底层原理：MySQL 执行 `LIMIT 100000, 20` 时，会先扫描前 `100000+20` 条数据，再丢弃前 100000 条，仅返回最后 20 条，扫描成本随 `offset` 增大线性增长；
- 现象：偏移量超过 10 万后，查询耗时从毫秒级飙升到秒级，甚至超时。

#### 三、深分页优化方案（按落地优先级排序）

##### 1. 游标分页（推荐，无性能衰减）

- 核心思路：用「有序唯一字段（如主键 ID、创建时间戳）」作为游标，替代 `offset`，通过 `WHERE 条件` 直接定位数据起始位置，避免全表扫描。
- 实现步骤：
    1. 确保排序字段是「唯一且有序」的（如主键 ID 自增、`create_time` + `id` 组合，避免排序冲突）；
    2. 前端首次查询：`pageNum=1`，后端返回 `pageSize` 条数据 + 最后一条数据的游标（如 `lastId=100020`）；
    3. 前端后续查询：传递 `lastId` 和 `pageSize`，后端执行 `SELECT * FROM t_user WHERE id > #{lastId} ORDER BY id LIMIT #{pageSize}`；
- 优点：查询时间复杂度 O (1)（依赖索引），支持无限深分页，无性能衰减；
- 缺点：不支持「跳页查询」（如直接跳转到第 1000 页），仅支持「上一页 / 下一页」滚动；
- 适用场景：无限滚动列表（如电商商品列表、信息流）。

##### 2. 覆盖索引优化（支持跳页，适合中小数据量）

- 核心思路：若必须支持跳页（如管理后台分页），通过「覆盖索引」减少扫描数据量 —— 仅扫描索引而非全表，提升 `LIMIT offset, pageSize` 效率。

- 实现步骤：

    1. 建立「排序字段 + 查询字段」的联合覆盖索引，避免回表（如查询 `id, name, age`，排序字段 `id`，则建立索引 `idx_id_name_age (id, name, age)`）；
    2. 优化 SQL：先通过覆盖索引查询出目标数据的主键 ID，再关联原表查询完整数据（减少大偏移量扫描）；

- 示例 SQL（优化前 vs 优化后）：

  sql











  ```sql
  -- 优化前（全表扫描，偏移量大时慢）
  SELECT id, name, age FROM t_user ORDER BY id LIMIT 100000, 20;
  
  -- 优化后（覆盖索引扫描，快速定位主键）
  SELECT t.id, t.name, t.age 
  FROM t_user t
  JOIN (
    SELECT id FROM t_user ORDER BY id LIMIT 100000, 20 -- 仅扫描索引，速度快
  ) tmp ON t.id = tmp.id;
  ```



- 优点：支持跳页查询，改动小；

- 缺点：偏移量极端大时（如百万级）仍有性能损耗，索引维护成本增加；

- 适用场景：管理后台、数据导出等必须跳页的场景，数据量不超过千万级。

##### 3. 预计算分块（适合超大数据量，支持跳页）

- 核心思路：提前将数据按「分块大小」预计算，存储分块信息（如每 1000 条数据为一个块，记录块的起始 ID 和结束 ID），查询时先定位块，再在块内小范围分页。

- 实现步骤：

    1. 建立分块表



     ```
     t_user_chunk
     ```

     ，存储分块信息：

     | chunk_id（块 ID） | start_id（块起始 ID） | end_id（块结束 ID） | chunk_size（块内条数） |
     | ----------------- | --------------------- | ------------------- | ---------------------- |
     | 1                 | 1                     | 1000                | 1000                   |
     | 2                 | 1001                  | 2000                | 1000                   |

2. 查询时，先计算目标页码所在的块：`chunk_id = ceil(pageNum * pageSize / chunk_size)`；

3. 从分块表获取块的 `start_id`，计算块内偏移量：`inner_offset = (pageNum-1)*pageSize % chunk_size`；

4. 执行 SQL：`SELECT * FROM t_user WHERE id BETWEEN #{start_id} AND #{end_id} ORDER BY id LIMIT #{inner_offset}, #{pageSize}`；

- 优点：支持跳页，超大数据量（亿级）下性能稳定；

- 缺点：需维护分块表（可通过定时任务更新），适合静态或低频更新的数据；

- 适用场景：亿级数据的分页查询，如数据仓库、历史订单查询。

##### 4. 其他补充方案

- 限制最大页码：前端限制用户跳页的最大页码（如最多支持 1000 页），引导用户通过筛选条件缩小查询范围（如按时间、分类筛选）；
- 异步导出：对于超深分页（如导出全部数据），不直接分页查询，而是通过异步任务生成 CSV 文件，用户下载（避免实时查询压力）。