## [26本作业帮OC面经](https://www.nowcoder.com/discuss/710960260051169280?sourceSSR=users)



### 一、三面面试题（40min，偏基础 + 算法）



#### 1. 分布式事务的四个模式（TCC/2PC/SAGA/ 本地消息表）



核心是「解决跨服务数据一致性」的四种经典方案，重点突出各自核心逻辑和适用场景：

| 模式                       | 核心定义                                                     | 核心流程                                                     | 适用场景                       | 优缺点                                   |
| -------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------ | ---------------------------------------- |
| TCC（Try-Confirm-Cancel）  | 基于业务逻辑的 “补偿型” 分布式事务，无锁设计                 | 1. Try：资源检查 + 预留（如扣减库存前锁定库存）；2. Confirm：确认执行（实际扣库存）；3. Cancel：取消预留（释放库存） | 短事务、高一致性（如支付）     | 优点：无锁、性能好；缺点：侵入业务代码   |
| 2PC（两阶段提交）          | 基于协调者 + 参与者的 “强一致性” 协议（之前聊过，补充到四模式） | 1. 准备阶段：参与者执行操作不提交，反馈状态；2. 提交阶段：协调者统一通知提交 / 回滚 | 短事务、强一致性（如银行转账） | 优点：强一致；缺点：阻塞、协调者单点风险 |
| SAGA                       | 长事务拆分为多个本地事务，通过 “补偿事务” 回滚               | 1. 正向流程：T1→T2→…→Tn（每个 Ti 是本地事务）；2. 异常回滚：Cn→…→C2→C1（Ci 是 Ti 的补偿） | 长事务、弱一致性（如订单履约） | 优点：无阻塞、适配长事务；缺点：一致性弱 |
| 本地消息表（可靠消息队列） | 基于 “消息可靠性” 的最终一致性方案，无侵入业务               | 1. 本地事务 + 写消息表（原子操作）；2. 消息表同步到 MQ；3. 消费端消费消息执行远程事务 | 弱一致性、高吞吐（如缓存同步） | 优点：无侵入、易实现；缺点：一致性延迟   |

#### 2. 分布式协议（Raft/Kraft）



##### （1）Raft 协议（分布式一致性协议）



- 核心目标：解决分布式系统中 “数据复制一致性”（如集群选主、日志同步）。
- 核心角色：
    - Leader（领导者）：处理客户端请求，同步日志到追随者。
    - Follower（追随者）：被动接收日志，参与投票。
    - Candidate（候选人）：选举阶段的临时角色。
- 核心流程：
    1. 选举：任期（Term）开始，Follower 超时未收到 Leader 心跳，转为 Candidate，发起投票，获得多数票则成为 Leader。
    2. 日志复制：Leader 接收请求后写入日志，同步到所有 Follower，多数 Follower 确认后，Leader 提交日志并返回结果。
    3. 安全性：任期内仅一个 Leader；日志仅从 Leader 同步；已提交的日志不会被覆盖。

##### （2）Kraft（Kafka 的 Raft 实现）



- 背景：替代 Kafka 旧版依赖的 ZooKeeper（简化架构、提升稳定性）。
- 核心改进：
    - 用 Kafka 自身的 Raft 集群（Controller Quorum）替代 ZooKeeper，管理元数据（主题、分区、副本信息）。
    - Controller Quorum 由 3/5 个 Broker 组成，通过 Raft 协议保证元数据一致性。
    - 优势：减少跨进程通信开销，元数据更新更快，集群部署更简单。

#### 3. Go 中的结构体能进行比较吗？



- 结论：**部分可以，取决于结构体的字段类型**。

- 可比较的情况：结构体所有字段都是 “可比较类型”（int、string、bool、指针、数组、其他可比较结构体等）。

    - 示例：

      go

      运行

      ```
      type Person struct {
          Name string
          Age  int
      }
      p1 := Person{"Alice", 20}
      p2 := Person{"Alice", 20}
      fmt.Println(p1 == p2) // 输出 true
      ```



- 不可比较的情况：结构体包含 “不可比较类型”（slice、map、channel），编译报错。

    - 示例：

      go

      运行

      ```
      type Data struct {
          List []int // slice不可比较
      }
      d1 := Data{[]int{1,2}}
      d2 := Data{[]int{1,2}}
      fmt.Println(d1 == d2) // 编译报错：invalid operation: d1 == d2 (struct containing []int cannot be compared)
      ```



#### 4. 算法：轮流打印奇偶数（Go/Java 实现）



核心思路：用「信号量」或「channel」实现线程 / 协程同步，交替执行。

##### Go 实现（channel 同步）：



go

运行

```
package main

import (
	"fmt"
	"sync"
)

func main() {
	var wg sync.WaitGroup
	oddChan := make(chan struct{})  // 奇数打印信号
	evenChan := make(chan struct{}) // 偶数打印信号

	wg.Add(2)

	// 打印奇数（1,3,5...9）
	go func() {
		defer wg.Done()
		for i := 1; i <= 10; i += 2 {
			<-oddChan // 等待奇数信号
			fmt.Println("奇数:", i)
			evenChan <- struct{}{} // 发送偶数信号
		}
	}()

	// 打印偶数（2,4,6...10）
	go func() {
		defer wg.Done()
		for i := 2; i <= 10; i += 2 {
			<-evenChan // 等待偶数信号
			fmt.Println("偶数:", i)
			if i < 10 { // 最后一个偶数后不发送，避免死锁
				oddChan <- struct{}{}
			}
		}
	}()

	oddChan <- struct{}{} // 启动第一个奇数打印
	wg.Wait()
	close(oddChan)
	close(evenChan)
}
```



##### Java 实现（Lock+Condition）：



java

运行

```
import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

public class PrintOddEven {
    private static final Lock lock = new ReentrantLock();
    private static final Condition oddCond = lock.newCondition();
    private static final Condition evenCond = lock.newCondition();
    private static int num = 1;

    public static void main(String[] args) {
        // 打印奇数
        new Thread(() -> {
            lock.lock();
            try {
                for (int i = 1; i <= 10; i += 2) {
                    System.out.println("奇数:" + num++);
                    evenCond.signal(); // 唤醒偶数线程
                    if (i < 9) oddCond.await(); // 等待下一次奇数信号
                }
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            } finally {
                lock.unlock();
            }
        }).start();

        // 打印偶数
        new Thread(() -> {
            lock.lock();
            try {
                for (int i = 2; i <= 10; i += 2) {
                    evenCond.await(); // 等待偶数信号
                    System.out.println("偶数:" + num++);
                    oddCond.signal(); // 唤醒奇数线程
                }
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            } finally {
                lock.unlock();
            }
        }).start();
    }
}
```



### 二、二面面试题（偏 MySQL / 网络 / 算法）



#### 1. MySQL 事务介绍及四大特性保证



##### （1）事务定义：



一组 SQL 操作构成的逻辑单元，要么全部执行成功，要么全部失败回滚，保证数据一致性。

##### （2）ACID 四大特性及实现方式：



| 特性        | 定义                                                         | 实现方式                                                     |
| ----------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 原子性（A） | 事务不可分割，要么全执行，要么全回滚                         | undo log（撤销日志）：记录事务执行前的状态，回滚时通过 undo log 恢复数据 |
| 一致性（C） | 事务执行前后，数据从合法状态变为另一个合法状态（如转账后总金额不变） | 依赖原子性、隔离性、持久性 + 约束校验（主键、外键、非空）    |
| 隔离性（I） | 并发事务相互干扰，避免脏读、不可重复读、幻读                 | 锁机制（行锁、表锁、Next-Key Lock） + MVCC（多版本并发控制） |
| 持久性（D） | 事务提交后，数据持久化到磁盘，不会因宕机丢失                 | redo log（重做日志）：事务执行时记录数据修改，宕机后通过 redo log 恢复已提交事务 |

#### 2. MySQL 三个日志（redo/undo/binlog）区别及提交时机



##### （1）三大日志核心区别：



| 日志类型 | 核心作用                   | 存储内容                                    | 所属层          |
| -------- | -------------------------- | ------------------------------------------- | --------------- |
| redo log | 保证持久性，恢复已提交事务 | 物理日志（如 “页号 + 偏移量 + 修改后数据”） | InnoDB 存储引擎 |
| undo log | 保证原子性，事务回滚       | 逻辑日志（如 “插入→删除”“更新→原值”）       | InnoDB 存储引擎 |
| binlog   | 主从复制、数据备份         | 逻辑日志（SQL 语句或行级修改）              | MySQL 服务器层  |

##### （2）提交时机：



- redo log：事务执行过程中 “循环写入”（先写 redo log buffer，再刷盘），事务提交时调用 `fsync` 强制刷盘（确保持久化）。
- undo log：事务执行时随 SQL 操作同步写入，事务提交后不会立即删除，后续由 purge 线程清理（用于 MVCC 读）。
- binlog：事务提交的 “最后一步” 写入（先写 binlog，再提交事务），确保 binlog 与 redo log 的一致性（二阶段提交）。
- 结论：redo log 和 undo log 提交时机**不同**，redo log 在提交时刷盘，undo log 随事务执行同步写入。

#### 3. Buffer Pool（缓冲池）介绍及存储内容



##### （1）核心定义：



InnoDB 的核心内存结构，是一块用于缓存磁盘数据的内存区域，目的是**减少磁盘 IO**（内存 IO 速度是磁盘的 10 万倍）。

##### （2）存储内容：



- 数据页（表数据）：从磁盘加载的表数据页，缓存后查询无需访问磁盘。
- 索引页：索引对应的 B + 树节点数据，加速索引查询。
- undo 页：undo log 的缓存，减少 undo log 的磁盘写入。
- 插入缓冲（Insert Buffer）、自适应哈希索引（AHI）等优化结构。

##### （3）核心机制：



- LRU 算法：缓存淘汰策略（最近最少使用的页优先淘汰），优化为 “midpoint 插入”（避免频繁访问的小数据页淘汰热点页）。
- 脏页刷新：Buffer Pool 中的数据修改后成为 “脏页”，后台线程（如 page cleaner）异步刷盘到磁盘，不阻塞用户请求。

#### 4. 分库分表的核心原则



1. **数据均匀分布**：分片键（如 user_id、create_time）需保证数据分散到各个库 / 表，避免某库 / 表数据量过大（倾斜）。
2. **业务查询对齐**：分片键需是高频查询字段（如按 user_id 分表，查询用户订单时直接定位分片），减少跨库跨表查询。
3. **可扩展性**：分片规则需支持后续扩容（如按范围分表可直接追加新表，哈希分表需提前规划分片数）。
4. **最小化跨库操作**：避免频繁跨库 join、跨库事务（如分库后尽量在同一库内完成业务操作）。
5. **兼容业务变更**：分片规则需考虑业务增长（如时间分表按 “月” 分，后续可调整为 “周” 分）。

#### 5. QUIC 协议及可靠性保证



##### （1）QUIC 核心：



基于 UDP 的可靠传输协议，HTTP3.0 的底层协议，解决 TCP 握手慢、队头阻塞等问题。

##### （2）可靠性保证机制：



1. **序列号与确认应答**：每个数据包分配唯一序列号，接收方返回确认应答（ACK），支持累计应答和选择性应答。
2. **超时重传与快重传**：发送方超时未收到 ACK 则重传，收到 3 个重复 ACK 则触发快重传（类似 TCP）。
3. **流量控制**：基于滑动窗口机制，避免接收方缓冲区溢出。
4. **拥塞控制**：支持 Cubic、BBR 等拥塞控制算法，动态调整发送速率，避免网络拥堵。
5. **连接迁移**：基于 “连接 ID” 标识连接，而非 IP + 端口，断网重连或切换网络（4G→WiFi）时不中断连接。

#### 6. HTTP1.0/1.1/2.0 区别及 HTTP3.0 浏览器设置



##### （1）核心区别：



| 版本 | 核心改进                     | 缺点                                     |
| ---- | ---------------------------- | ---------------------------------------- |
| 1.0  | 无连接、无状态               | 连接开销大（每次请求建连接）             |
| 1.1  | 长连接（keep-alive）、管线化 | 队头阻塞（同一连接请求串行）             |
| 2.0  | 二进制帧、多路复用、头部压缩 | TCP 层队头阻塞（数据包丢失影响整个连接） |

##### （2）HTTP3.0 浏览器设置：



- HTTP3.0 基于 QUIC，主流浏览器（Chrome、Firefox、Edge）默认支持，无需手动设置。
- 验证方式：打开浏览器开发者工具（F12）→ Network → 刷新页面，查看请求的 “Protocol” 字段，显示 “h3” 即为 HTTP3.0。

#### 7. 断网后 TCP/UDP 连接是否存在？



- TCP 连接

  ：存在 “逻辑连接”，但不可用。

    - TCP 是面向连接的协议，连接状态（如 ESTABLISHED）存储在两端内核中，断网后状态不会立即消失。
    - 断网后无数据传输，双方会通过 “保活计时器”（默认 2 小时）检测连接，超时后标记连接为 CLOSED。
    - 实际效果：断网期间发送数据会失败，重连后需重新建立 TCP 连接。

- UDP 连接

  ：不存在连接。

    - UDP 是无连接协议，两端无 “连接状态”，仅通过 IP + 端口发送数据。
    - 断网后数据无法送达，但 UDP 本身不维护连接，断网恢复后可直接发送数据，无需重新建立连接。

#### 8. Kafka 顺序消费及优先级实现



##### （1）顺序消费保证（之前重点讲过，简洁回顾）：



- 生产端：同一业务消息发送到同一 Topic 的同一 Partition（分区内消息 FIFO）。
- 消费端：一个 Partition 仅被同一 Consumer Group 的一个消费者实例消费，手动提交 Offset。

##### （2）Kafka 消息优先级实现：



Kafka 本身不支持消息级优先级，但可通过以下方案实现：

1. **Topic 分级**：创建高 / 中 / 低优先级 Topic（如`topic-high`、`topic-normal`），消费者优先订阅高优先级 Topic。
2. **分区优先级**：同一 Topic 内，将高优先级消息发送到指定 Partition（如 Partition 0），消费者优先消费该 Partition。
3. **消费组内优先级**：通过自定义消费逻辑，消费者拉取消息后先过滤高优先级消息（如消息中携带`priority`字段），优先处理。

#### 9. 算法：打家劫舍（DP）



##### 题目要求：



你是一个专业的小偷，计划偷窃沿街的房屋。每间房内都藏有一定的现金，影响你偷窃的唯一制约因素就是相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警。给定一个代表每个房屋存放金额的非负整数数组，计算你不触动警报装置的情况下，能够偷窃到的最高金额。

##### 核心思路：DP 动态规划



- 状态定义：`dp[i]` 表示前 i 间房屋能偷窃的最高金额。
- 转移方程：`dp[i] = max(dp[i-1], dp[i-2] + nums[i])`（选第 i 间则不能选 i-1，选 i-1 则不选 i）。
- 空间优化：无需数组，用两个变量存储`dp[i-1]`和`dp[i-2]`。

##### Java 实现：



java

运行

```
public int rob(int[] nums) {
    if (nums == null || nums.length == 0) return 0;
    if (nums.length == 1) return nums[0];
    int prevPrev = nums[0]; // dp[0]
    int prev = Math.max(nums[0], nums[1]); // dp[1]
    for (int i = 2; i < nums.length; i++) {
        int curr = Math.max(prev, prevPrev + nums[i]);
        prevPrev = prev;
        prev = curr;
    }
    return prev;
}
```



#### 10. DFS 算法（示例：二叉树路径总和）



##### 题目要求：



给定一个二叉树和一个目标和，判断该树中是否存在根节点到叶子节点的路径，这条路径上所有节点值相加等于目标和。

##### Java 实现（DFS 递归）：



java

运行

```
class TreeNode {
    int val;
    TreeNode left;
    TreeNode right;
    TreeNode(int x) { val = x; }
}

public boolean hasPathSum(TreeNode root, int targetSum) {
    if (root == null) return false;
    // 叶子节点，判断当前值是否等于剩余目标和
    if (root.left == null && root.right == null) {
        return root.val == targetSum;
    }
    // 递归遍历左右子树，目标和减去当前节点值
    return hasPathSum(root.left, targetSum - root.val) 
        || hasPathSum(root.right, targetSum - root.val);
}
```