Redis 与数据库（如 MySQL）的一致性核心是 **“缓存与数据库的读写协同”**—— 避免出现 “缓存有脏数据”“缓存与数据库数据不一致” 的情况。延迟双删是常用策略，但并非唯一选择，其他策略需根据 **业务一致性要求（强一致 / 最终一致）、读写频率、性能需求** 灵活选择。

### 一、先明确：一致性的核心矛盾与前提

#### 1. 核心矛盾

缓存与数据库的操作无法 “原子化”（跨系统操作无全局事务），因此会出现两种典型不一致场景：

- 写操作：先更缓存还是先更数据库？（顺序错误导致脏数据）；
- 读操作：缓存缺失 / 失效时，如何避免 “缓存击穿 / 穿透”，同时保证读取到最新数据。

#### 2. 前提约定

- 优先采用 **“缓存作为数据库的只读副本”**（缓存不直接写入，仅通过数据库更新同步），避免缓存与数据库双向写；
- 明确业务一致性等级：多数互联网场景（如商品列表、用户信息）可接受 **最终一致**（毫秒 / 秒级同步延迟），仅核心场景（如订单支付、库存扣减）需 **强一致**。

### 二、不使用延迟双删的核心策略（按一致性等级分类）

#### （一）最终一致场景（互联网主流选择，性能优先）

最终一致允许短时间内缓存与数据库不一致，但需通过机制保证 “最终同步”，适合读多写少、对一致性要求不严格的场景（如商品详情、新闻列表）。

##### 策略 1：Cache-Aside 模式（缓存旁路，最经典）

**核心思想：读写操作都绕开缓存，直接操作数据库，再同步更新缓存**，是延迟双删的替代基础方案。

###### 1. 读流程（Cache-Aside Read）

```plaintext
1. 客户端查询缓存 → 命中则直接返回；
2. 缓存未命中 → 客户端查询数据库；
3. 从数据库获取数据后，同步写入缓存（更新缓存）；
4. 返回数据给客户端。
```

###### 2. 写流程（Cache-Aside Write）

```plaintext
1. 客户端先更新数据库（MySQL）；
2. 数据库更新成功后，删除缓存（而非更新缓存）；
3. 后续读请求会因缓存缺失，从数据库加载最新数据并刷新缓存。
```

###### 核心优势（为何能保证最终一致？）

- 写操作 “先更库，后删缓存”：即使删缓存失败，后续读请求会从数据库加载最新数据刷新缓存，最终达成一致；
- 避免 “先更缓存，后更库” 的致命问题：若更缓存后数据库更新失败，缓存会残留脏数据，且长期无法修正。

###### 关键优化（避免删缓存失败导致的不一致）

- 删缓存失败处理：将 “删除缓存” 操作放入 **消息队列（如 RocketMQ/Kafka）** 重试（最多重试 3 次），确保缓存最终被删除；
- 缓存过期时间兜底：给缓存设置合理的 TTL（如 5 分钟），即使删缓存失败，缓存到期后也会自动失效，从数据库加载最新数据。

###### 适用场景：读多写少、最终一致、性能要求高（如商品详情、用户资料查询）。

##### 策略 2：Write-Through 模式（写透缓存）

**核心思想：写操作先同步更新缓存和数据库，读操作直接查缓存**—— 缓存与数据库的更新是 “同步原子化”（逻辑上），一致性比 Cache-Aside 更强。

###### 1. 写流程（核心）

```plaintext
1. 客户端写入数据时，先更新缓存；
2. 缓存更新成功后，再同步更新数据库；
3. 数据库更新成功后，返回“写入成功”给客户端。
```

###### 2. 读流程


```plaintext
1. 客户端直接查询缓存 → 命中则返回；
2. 未命中 → （可选）查询数据库并刷新缓存，返回数据（部分实现会省略此步，要求写操作必须先初始化缓存）。
```

###### 核心优势：

- 强最终一致：写操作同步更新缓存和数据库，读操作始终从缓存获取数据，不会出现 “读旧数据” 的情况；
- 无缓存穿透风险：写操作已初始化缓存，读操作不会直接穿透到数据库。

###### 缺点：

- 写性能差：同步更新缓存 + 数据库，写操作延迟翻倍（如数据库更新需 10ms，缓存更新需 2ms，总延迟 12ms）；
- 数据库更新失败会导致缓存脏数据：需配合数据库事务 + 缓存回滚（如数据库更新失败，删除已更新的缓存），实现复杂度高。

###### 适用场景：写操作频率低、对一致性要求高、读操作需极致性能（如金融核心数据、配置中心）。

##### 策略 3：Write-Back 模式（写回缓存 / 异步刷库）

**核心思想：写操作先更新缓存，数据库异步批量更新**—— 性能最优，但一致性最弱（仅适合非核心场景）。

###### 1. 写流程


```plaintext
1. 客户端写入数据时，仅更新缓存（标记缓存为“脏数据”）；
2. 缓存异步（如定时任务、缓存满时）将“脏数据”批量刷写到数据库；
3. 刷写成功后，标记缓存为“干净数据”。
```

###### 2. 读流程：与 Write-Through 一致（直接读缓存）。

###### 核心优势：

- 写性能极致：仅操作缓存（内存操作，微秒级），数据库异步批量刷写，适合高并发写场景；
- 读性能优：读操作直接查缓存，无穿透。

###### 缺点：

- 一致性最弱：缓存更新后数据库未刷写前，服务宕机 / 缓存崩溃会导致数据丢失；
- 实现复杂：需处理缓存脏数据标记、批量刷写、失败重试、数据合并（同一 key 多次写入仅刷写最终值）。

###### 适用场景：非核心数据、允许数据少量丢失、高并发写（如用户行为日志、临时统计数据）。

#### （二）强一致场景（核心业务，如库存、支付）

强一致要求 “缓存与数据库数据实时完全一致”，需通过 “分布式锁 + 原子操作” 实现，不依赖延迟双删。

##### 策略 4：分布式锁 + 串行化读写（强一致核心方案）

**核心思想：通过分布式锁（如 Redis Redlock、ZooKeeper）保证同一数据的读写操作串行执行，避免并发冲突**。

###### 完整流程（以库存扣减为例）

```plaintext
1. 客户端发起库存扣减请求，先获取分布式锁（锁key=商品ID）；
2. 加锁成功 → 查询数据库获取当前库存（避免缓存脏数据，强一致必须查库）；
3. 校验库存是否充足 → 充足则扣减数据库库存；
4. 数据库更新成功后，删除/更新缓存；
5. 释放分布式锁；
6. 加锁失败 → 重试或返回“系统繁忙”。
```

###### 核心保障：

- 串行化执行：同一商品的读写操作排队执行，不会出现 “并发写导致的库存超卖 / 数据不一致”；
- 先库后缓存：确保数据库是最新数据，缓存同步后与数据库一致。

###### 关键优化：

- 锁粒度：按 “数据 ID” 加锁（如商品 ID），而非全局锁，保证并发性能；
- 锁超时：设置合理的锁超时时间（如 3 秒），避免死锁；
- 缓存更新：数据库更新后，优先 “删除缓存”（而非更新），后续读请求自动刷新缓存，避免更新缓存失败导致的不一致。

###### 适用场景：核心业务强一致需求（如库存扣减、订单支付、余额变更）。

##### 策略 5：数据库 binlog + 缓存同步（最终一致增强版）

**核心思想：通过解析数据库 binlog，异步同步缓存，替代延迟双删，一致性更可靠**（本质是 Cache-Aside 模式的增强）。

###### 完整流程

1. 数据库开启 binlog（如 MySQL 的 ROW 格式 binlog）；
2. 部署 binlog 解析服务（如 Canal、MaxWell），实时监听数据库 binlog；
3. 写操作流程：
   - 客户端更新数据库；
   - 数据库生成 binlog；
   - binlog 解析服务捕获 binlog，提取 “更新的数据” 和 “操作类型”（insert/update/delete）；
   - 解析服务根据 binlog 内容，异步更新 / 删除缓存；
4. 读操作流程：与 Cache-Aside 一致。

###### 核心优势（比延迟双删更优）

- 一致性更可靠：延迟双删依赖 “两次删除缓存”，可能因第一次删失败 / 延迟导致不一致；binlog 同步是 “基于数据库最终状态” 的同步，只要数据库更新成功，缓存一定能同步；
- 无侵入：无需在业务代码中写 “删缓存” 逻辑，通过中间件异步处理，降低开发复杂度；
- 支持批量同步：binlog 可批量解析，适合高并发写场景。

###### 缺点：

- 引入中间件复杂度：需部署 Canal/MaxWell，维护成本增加；
- 存在短暂延迟：binlog 解析 + 缓存同步有毫秒级延迟，仍属于最终一致（但比延迟双删的延迟更可控）。

###### 适用场景：最终一致、高并发写、业务代码无侵入需求（如电商商品数据、用户订单列表）。

### 三、各策略对比与选型建议

| 策略                  | 一致性等级 | 读写性能     | 实现复杂度 | 适用场景                                   |
| --------------------- | ---------- | ------------ | ---------- | ------------------------------------------ |
| Cache-Aside（旁路）   | 最终一致   | 读优、写一般 | 低         | 读多写少、最终一致（如商品详情、用户资料） |
| Write-Through（写透） | 强最终一致 | 读优、写差   | 中         | 写少、强一致（如金融核心数据、配置中心）   |
| Write-Back（写回）    | 弱最终一致 | 读写均优     | 高         | 高并发写、允许少量丢失（如日志、临时数据） |
| 分布式锁 + 串行读写   | 强一致     | 写一般、读优 | 中         | 核心业务（库存、支付、余额）               |
| binlog + 缓存同步     | 最终一致   | 读写均优     | 中 - 高    | 高并发写、无侵入需求（电商商品、订单）     |

#### 选型核心原则：

1. 非核心场景（读多写少）→ 优先 **Cache-Aside**（简单、高效）；
2. 高并发写 + 无侵入 → 优先 **binlog + 缓存同步**（可靠、低耦合）；
3. 强一致需求 → 优先 **分布式锁 + 串行读写**（核心业务必备）；
4. 写少 + 强一致 → 可选 **Write-Through**（性能与一致性平衡）；
5. 允许数据丢失 + 高并发写 → 慎用 **Write-Back**（非核心场景）。

### 四、避坑指南（无论选哪种策略）

1. 永远避免 “先更缓存，后更数据库”：这是导致脏数据的最主要原因，即使加了延迟双删也可能因网络延迟失效；
2. 缓存必须设置 TTL：作为一致性兜底，即使同步机制失效，缓存到期后也会自动刷新；
3. 删缓存优先于更缓存：写操作后 “删除缓存” 比 “更新缓存” 更安全 —— 避免更新缓存失败导致的脏数据，后续读请求会自动刷新；
4. 高并发场景必加分布式锁：同一数据的并发写操作（如库存扣减），必须通过分布式锁串行化，否则会出现 “超卖”“数据不一致”。

### 总结

不使用延迟双删时，Redis 与数据库的一致性策略核心是 **“协同读写顺序 + 异步同步 / 串行化”**：

- 最终一致场景：用 Cache-Aside（简单）或 binlog 同步（可靠）；
- 强一致场景：用分布式锁 + 串行读写；
- 特殊场景：根据读写频率和一致性要求，选择 Write-Through/Write-Back。

核心目标是：**确保数据库是 “数据真相源”，缓存仅作为 “只读副本”，通过合理的读写协同和兜底机制，避免脏数据和不一致**。
