## [26本美团到家支付中台OC面经](https://www.nowcoder.com/feed/main/detail/a5b0ca8b57754c85b3363e56c8933184?sourceSSR=users)


二面果然更偏向 “深度 + 实践结合”，还夹杂了不少开放题和项目细节！下面按问题顺序给出 **面试级精准回答**，既覆盖原理，又贴合实际使用场景，方便你复盘和后续准备：

### 1. 常用消息队列（Kafka/RabbitMQ）如何保证顺序消费？会丢消息吗？



#### （1）保证顺序消费的核心逻辑



顺序消费的关键是 **“消息生产有序 + 存储有序 + 消费有序”**，Kafka 和 RabbitMQ 实现方式不同：

##### Kafka 顺序消费



- 生产端：同一业务线的消息，发送到

  同一个 Topic 的同一个 Partition

  （Kafka 分区内消息有序存储）。

    - 实现：指定分区键（如订单 ID），通过哈希算法将同一订单的消息路由到同一分区。

- 消费端：

    - 一个 Partition 只能被同一个 Consumer Group 中的 **一个消费者实例** 消费（避免多线程并发消费打乱顺序）。
    - 关闭自动提交 Offset，消费成功后手动提交（确保消息处理完成后再推进 Offset，避免漏消费导致顺序错乱）。

##### RabbitMQ 顺序消费



- 生产端：发送到 **同一个队列（Queue）**（RabbitMQ 队列内消息 FIFO 有序）。
- 消费端：
    - 关闭消费者的 “自动确认（autoAck=false）”，改为手动确认（basicAck）。
    - 单个队列仅启动 **一个消费者实例**（或使用 “排他队列”），避免多消费者并发消费；若需提高吞吐量，可按业务键拆分多个队列（如订单队列按用户 ID 分桶）。
    - 禁用 “消息预取（prefetchCount=1）”，确保消费者处理完一条消息后再获取下一条。

#### （2）是否会丢消息？



**会丢消息，但可通过配置避免**，核心丢消息场景及解决方案：

| 消息队列 | 丢消息场景                                                   | 避免方案                                                     |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Kafka    | 1. 生产端未确认消息发送成功；2. 服务器刷盘前宕机；3. 消费端未处理完消息就提交 Offset | 1. 生产端开启 `acks=all`（等待所有副本确认）；2. 开启分区副本（`replication.factor≥3`）；3. 消费端手动提交 Offset |
| RabbitMQ | 1. 生产端未确认消息投递成功；2. 队列未持久化，服务器宕机；3. 消费端未确认消息就宕机 | 1. 生产端开启 `publisher-confirm-type=correlated`（消息确认）；2. 队列 + 消息都设置为持久化（durable=true）；3. 消费端手动确认消息 |

### 2. 消息同步性怎么保证？



消息同步性核心是 **“生产 - 消费的顺序一致 + 数据一致性”**，分两种场景：

#### （1）严格顺序同步（如订单状态变更：创建→支付→发货）



- 用上述 “顺序消费” 方案，确保消息消费顺序与生产顺序一致。
- 消费端使用 “单线程处理”，避免并发导致的顺序错乱。
- 关键业务（如支付）可引入 “分布式锁”（如 Redis 锁），确保同一资源的消息串行处理。

#### （2）数据同步一致性（如缓存同步、数据库同步）



- 生产端：消息携带 “版本号” 或 “时间戳”，消费端按版本号更新（避免旧消息覆盖新消息）。
- 消费端：使用 “幂等性处理”（如数据库唯一索引、缓存键前缀 + 版本号），避免重复消费导致数据不一致。
- 关键场景：采用 “事务消息”（Kafka 事务消息、RabbitMQ 发布确认 + 回滚机制），确保业务操作与消息发送原子性（如订单创建成功后再发送消息）。

### 3. Kafka 和 RabbitMQ 哪个好用？



没有绝对好坏，**按业务场景选择**：

| 对比维度 | Kafka                                        | RabbitMQ                                                     |
| -------- | -------------------------------------------- | ------------------------------------------------------------ |
| 核心优势 | 高吞吐量（百万级 QPS）、高存储、适合大数据量 | 灵活路由（交换机模式）、低延迟、支持复杂队列类型（死信队列、延迟队列） |
| 适用场景 | 日志收集、大数据同步、秒杀削峰（高吞吐场景） | 业务消息（订单、支付）、RPC 通信、延迟任务（如订单超时取消） |
| 劣势     | 路由简单、延迟略高（毫秒级）                 | 吞吐量较低（万级 QPS）、不适合超大数据存储                   |
| 推荐选择 | 需处理海量数据、追求高吞吐                   | 业务逻辑复杂、需要灵活路由、低延迟场景                       |

### 4. Redis 为什么这么快？详细介绍 single memory loop？



#### （1）Redis 快的核心原因



1. **纯内存操作**：数据都存储在内存中，避免磁盘 IO 开销（内存 IO 速度是磁盘的 10 万倍以上）。
2. **单线程模型**：避免多线程上下文切换和锁竞争开销（Redis 6.0+ 引入多线程 IO，但核心处理仍单线程）。
3. **高效数据结构**：底层用 SDS、跳表、压缩列表等优化结构，查询 / 操作效率高（如跳表 O (log n) 查找）。
4. **IO 多路复用**：使用 epoll/kqueue 等 IO 多路复用机制，单线程处理成千上万的网络连接。
5. **精简的网络模型**：采用 “请求 - 响应” 模式，协议简单（Redis 协议是文本协议，解析快），减少通信开销。

#### （2）Single Memory Loop（单线程事件循环）



Redis 核心处理流程是 “单线程事件循环”，本质是 **“用一个线程处理所有客户端请求和内部任务”**，流程如下：

1. **初始化**：Redis 启动后，初始化事件处理器（epoll），监听端口（默认 6379），注册 “连接事件”（accept 事件）。

2. 事件循环

   ：进入无限循环，核心步骤：

    - **等待事件**：调用 `epoll_wait`，阻塞等待客户端连接、数据发送等 IO 事件。

    - 处理事件

      ：

        - 若为 “连接事件”：调用 `accept` 接收客户端连接，注册 “读事件”（等待客户端发送命令）。
        - 若为 “读事件”：读取客户端发送的命令（如 SET、GET），解析命令，执行对应的操作（如修改内存中的数据结构）。
        - 若为 “写事件”：将命令执行结果（如 OK、数据值）写入客户端连接，返回响应。

    - **处理内部任务**：循环中穿插处理内部任务（如过期键删除、RDB 持久化触发、集群同步）。

3. **核心优势**：无线程切换开销，无锁竞争，简化代码逻辑，充分利用 CPU 缓存。

4. **注意**：Redis 6.0+ 引入 “多线程 IO”，仅将 “读取命令” 和 “写入响应” 交给多线程处理，核心的 “命令执行” 仍为单线程，避免并发安全问题。

### 5. 字节开源的 noncopy buffer 了解吗？



字节开源的 noncopy buffer 核心是 **ByteBuf（基于 Netty 的 ByteBuf 优化）**，常见于字节内部框架（如 Volcengine RocketMQ、Kitex），核心设计目标是 **“零拷贝（Zero-Copy）”**，减少数据拷贝开销。

#### 核心原理



- 传统 Buffer 问题：数据在 “内核态 - 用户态”“不同 Buffer 之间” 频繁拷贝（如读取网络数据时，内核缓冲区→用户缓冲区→应用缓冲区，多次拷贝）。
- ByteBuf 优化：
    - 基于 “直接内存（Direct Memory）”：数据存储在堆外内存，避免内核态与用户态的拷贝（内核可直接访问直接内存）。
    - 切片（Slice）机制：对大 Buffer 进行切片，生成多个小 Buffer，共享底层数据，无需拷贝。
    - 复合 Buffer（CompositeByteBuf）：将多个小 Buffer 组合成一个逻辑 Buffer，底层数据不拷贝，仅维护索引。
- 应用场景：高吞吐的网络通信（如 RPC、消息队列），减少拷贝开销，提升性能。

### 6. Redis 的 PV 和 UV 使用场景及实现



#### （1）PV（页面浏览量）：统计页面被访问的总次数



- 使用场景：网站首页 PV、文章阅读量、商品详情页访问量。
- 实现方案：
    - 核心数据结构：`String`（单键计数）或 `HyperLogLog`（海量数据去重统计，误差 < 2%）。
    - 具体实现：
        1. 简单场景：用 `INCR key`（如 `INCR pv:homepage:20241117`），按日期拆分键，方便统计每日 PV。
        2. 海量场景：用 `PFADD pv:all:20241117 user1 user2 ...`（HyperLogLog），`PFCOUNT pv:all:20241117` 获取总 PV（自动去重，适合千万级用户访问）。

#### （2）UV（独立访客数）：统计访问页面的独立用户数（去重）



- 使用场景：网站每日独立访客、活动参与独立用户数。
- 实现方案：
    - 核心数据结构：`HyperLogLog`（首选，省内存）或 `Set`（精准去重，适合小规模数据）。
    - 具体实现：
        1. 海量场景（千万级用户）：`PFADD uv:homepage:20241117 user_id1 user_id2 ...`，`PFCOUNT` 获取 UV（12KB 可统计 2^64 个数据）。
        2. 精准场景（万级用户）：`SADD uv:activity:1001 user_id`，`SCARD uv:activity:1001` 获取 UV（支持精准去重，但内存占用随用户数增长）。

### 7. Redis 的 RDB 操作、Async-fork 介绍，为什么要更快？如何解决数据不一致？



#### （1）RDB 操作核心



RDB 是 Redis 的 “快照持久化”，将某一时刻的内存数据以二进制文件（dump.rdb）形式保存到磁盘，核心触发方式：手动触发（`SAVE`/`BGSAVE`）、自动触发（配置 `save 900 1` 等规则）。

#### （2）Async-fork 介绍



- 背景：传统 `BGSAVE` 会调用 `fork()` 创建子进程，`fork()` 过程中会 “拷贝父进程页表”（虽然是写时复制，但页表拷贝仍可能阻塞主线程，尤其是内存大时）。
- Async-fork 优化：Redis 4.0+ 引入，将 `fork()` 操作 “异步化”—— 主线程发起 `fork()` 后，不阻塞等待子进程创建完成，而是继续处理客户端请求，子进程创建成功后再开始快照。
- 实现：依赖操作系统的 “异步 fork” 支持（如 Linux 的 `clone3()` 系统调用），减少主线程阻塞时间。

#### （3）为什么要更快？



- 核心需求：减少 `fork()` 和快照过程对主线程的阻塞，避免影响 Redis 服务的响应时间（尤其是大内存场景，如 10GB 内存，传统 `fork()` 可能阻塞数百毫秒）。
- 业务价值：保证高吞吐场景下的服务可用性，避免因持久化导致的请求超时。

#### （4）如何解决数据不一致？



RDB 是 “全量快照”，存在 “快照期间数据变更” 导致的 “最终一致性” 问题，解决方案：

1. 结合 AOF 持久化：开启 `aof-use-rdb-preamble yes`（Redis 7.0+ 默认），AOF 文件开头包含 RDB 快照，后续追加命令日志，兼顾 RDB 的快速恢复和 AOF 的数据完整性。
2. 合理配置快照触发规则：避免过于频繁的快照（如每小时一次），减少快照期间的数据变更量。
3. 主从复制同步：从节点通过 RDB 全量同步 + AOF 增量同步，确保从节点数据与主节点一致。

### 8. 分库分表介绍，一般分表用什么字段？



#### （1）分库分表核心



- 背景：单库单表数据量过大（如千万级 +），导致查询 / 写入性能下降，分库分表将数据拆分到多个库、多个表中，分散压力。
- 分类：
    - 水平拆分（按行拆分）：将同一表的数据按规则拆分到多个表（如订单表按用户 ID 分表），最常用。
    - 垂直拆分（按列拆分）：将表的大字段（如 text 字段）拆分到独立表（如用户表拆分为用户基本表 + 用户详情表），较少用。

#### （2）分表常用字段（分片键选择）



核心原则：**分片键需均匀分布数据，且符合业务查询场景**，常用字段：

1. 用户 ID（如 `user_id`）：适合 “按用户维度查询” 的场景（如用户订单、用户账单），数据分布均匀，查询时可直接通过用户 ID 定位分片。
2. 时间字段（如 `create_time`）：适合 “按时间维度查询” 的场景（如日志表、订单表按日期分表），便于归档历史数据，查询时按时间范围定位分片。
3. 业务主键（如 `order_id`）：适合 “按业务 ID 查询” 的场景（如订单表按订单 ID 哈希分表），需确保主键分布均匀（避免哈希倾斜）。

- 避坑：不选择 “非查询高频字段”（如状态字段）、“分布不均字段”（如性别字段）作为分片键。

### 9. MVCC 和 Next-Key Lock 介绍，如何分工合作？



#### （1）MVCC（多版本并发控制）



- 核心：InnoDB 实现 “隔离性” 的基础，通过 “数据版本链 + undo 日志”，让不同事务看到不同版本的数据，避免读写冲突（读不加锁，写加行锁）。
- 实现：
    - 每行数据包含 `DB_TRX_ID`（事务 ID）、`DB_ROLL_PTR`（undo 日志指针）。
    - 事务启动时生成 “Read View”（读视图），通过对比 `DB_TRX_ID` 和 Read View，判断数据版本是否可见。
- 作用：实现 “读已提交（RC）” 和 “可重复读（RR）” 隔离级别，提升并发读性能。

#### （2）Next-Key Lock（next-key 锁）



- 核心：InnoDB 的 “行锁 + 间隙锁” 组合，用于解决 “幻读” 问题（RR 隔离级别默认开启）。
- 实现：
    - 行锁：锁定索引对应的行数据。
    - 间隙锁：锁定索引之间的 “间隙”（如索引值 10、20 之间的间隙），防止其他事务插入数据。
    - Next-Key Lock 锁定范围：`(左边界, 右边界]`（如索引值 10 对应的 next-key 锁是 `(-∞, 10]`）。
- 作用：在 RR 隔离级别下避免幻读，保证事务隔离性。

#### （3）分工合作



- MVCC 负责 “读操作”：提供非锁定读（快照读），让读事务无需等待写事务释放锁，提升并发读性能。
- Next-Key Lock 负责 “写操作”：写事务（INSERT/UPDATE/DELETE）加 next-key 锁，防止其他事务插入数据导致幻读，保证写操作的原子性和隔离性。
- 协同效果：RR 隔离级别下，既通过 MVCC 实现高效并发读，又通过 next-key 锁避免幻读，平衡性能和隔离性。

### 10. HashMap 底层介绍，线程安全吗？线程安全的是哪个？为什么不能存 NULL 值？



#### （1）HashMap 底层实现（JDK 8+）



- 核心结构：`数组 + 链表/红黑树`。
- 存储流程：
    1. 计算 key 的哈希值：`hash(key) = (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16)`（高 16 位异或低 16 位，减少哈希冲突）。
    2. 计算数组索引：`index = (数组长度 - 1) & hash(key)`（数组长度为 2 的幂，保证索引均匀分布）。
    3. 冲突处理：
        - 链表长度 ≤ 8：数据存入链表（尾插法）。
        - 链表长度 > 8 且数组长度 ≥ 64：链表转为红黑树（查询效率从 O (n) 提升到 O (log n)）。
- 扩容机制：负载因子默认 0.75，数组使用率达到阈值后，扩容为原来的 2 倍，重新哈希迁移数据。

#### （2）线程安全吗？



**不安全**，核心线程安全问题：

- 扩容时的 “环形链表” 问题（JDK 7 及之前，头插法导致）。
- 并发读写时的 “数据覆盖” 问题（如两个线程同时写入同一个索引位置）。
- 迭代时的 “快速失败（fail-fast）” 问题（迭代过程中修改数据，抛出 `ConcurrentModificationException`）。

#### （3）线程安全的实现类



- `Hashtable`：所有方法加 `synchronized` 锁，效率低（全局锁）。
- `ConcurrentHashMap`：JDK 7 用 “分段锁”，JDK 8+ 用 “CAS + synchronized 行锁”，效率高（支持并发读写）。
- 推荐使用 `ConcurrentHashMap`（性能优于 Hashtable）。

#### （4）为什么不能存 NULL 值？



**HashMap 可以存 NULL 值（key 和 value 都可以）**！不能存 NULL 值的是 `Hashtable` 和 `ConcurrentHashMap`（JDK 8+ 支持 value 为 NULL，key 仍不能为 NULL）。

- `Hashtable` 不能存 NULL 的原因：设计时将 NULL 视为 “无效键”，`put` 时若 key 为 NULL 会抛出 `NullPointerException`。
- `ConcurrentHashMap` key 不能为 NULL 的原因：并发场景下，无法区分 “key 为 NULL” 和 “key 不存在”（如 `get(null)` 返回 NULL，无法判断是 key 不存在还是 value 为 NULL），可能导致业务逻辑错误。

### 11. SQL：找出及格的学生



假设表名 `student`，字段 `id`（学生 ID）、`name`（姓名）、`score`（分数），及格线为 60 分：

sql

```
SELECT id, name, score
FROM student
WHERE score >= 60;
```



- 若需按科目筛选（如数学及格），假设表含 `subject` 字段：

sql

```
SELECT id, name, subject, score
FROM student
WHERE subject = '数学' AND score >= 60;
```



### 12. 算法：判断一棵二叉树是否左右对称



#### 核心思路：递归判断 “左子树的左节点 == 右子树的右节点” 且 “左子树的右节点 == 右子树的左节点”。



java

运行

```
class TreeNode {
    int val;
    TreeNode left;
    TreeNode right;
    TreeNode(int x) { val = x; }
}

public boolean isSymmetric(TreeNode root) {
    if (root == null) return true;
    // 递归判断左右子树是否对称
    return isSymmetric(root.left, root.right);
}

private boolean isSymmetric(TreeNode left, TreeNode right) {
    // 两个节点都为 null，对称
    if (left == null && right == null) return true;
    // 一个为 null，一个不为 null，不对称
    if (left == null || right == null) return false;
    // 节点值相等，且左子树的左 == 右子树的右，左子树的右 == 右子树的左
    return (left.val == right.val) 
        && isSymmetric(left.left, right.right) 
        && isSymmetric(left.right, right.left);
}
```



### 13. QUIC 介绍



QUIC（Quick UDP Internet Connections）是 Google 设计的 “基于 UDP 的可靠传输协议”，核心目标是替代 TCP，解决 TCP 握手慢、队头阻塞等问题。

#### 核心特性：



1. **快速握手**：1-RTT 完成握手（甚至 0-RTT 重连），无需 TCP 的 3 次握手，减少连接建立时间。
2. **无队头阻塞**：TCP 是 “字节流协议”，一个数据包丢失会阻塞后续所有数据包；QUIC 按 “流（Stream）” 传输，不同流独立，一个流的数据包丢失不影响其他流。
3. **内置 TLS 加密**：默认加密传输（基于 TLS 1.3），无需额外配置 HTTPS。
4. **连接迁移**：基于 “连接 ID” 标识连接，而非 IP + 端口，支持手机切换网络（如 4G 切 WiFi）时不中断连接。
5. **拥塞控制**：支持 Cubic、BBR 等拥塞控制算法，性能优于 TCP。

- 应用：HTTP/3 基于 QUIC 实现，目前已被 Chrome、Firefox 等浏览器支持。

### 14. HTTP 1.0 到 3.0 主要更新



#### （1）HTTP 1.0（1996）



- 核心特性：无连接（每次请求建立新连接，响应后关闭）、无状态（不记录会话信息）。
- 缺点：连接开销大（三次握手 / 四次挥手）、队头阻塞（同一连接下请求串行）。

#### （2）HTTP 1.1（1999）



- 核心更新：
    1. 长连接（默认 `Connection: keep-alive`）：同一连接可处理多个请求，减少连接开销。
    2. 管线化（Pipelining）：同一连接下可并行发送多个请求，但响应仍需串行返回（仍有队头阻塞）。
    3. 支持方法扩展（如 PUT、DELETE）、缓存控制（Cache-Control）、Chunked 编码（分块传输）。
- 缺点：队头阻塞未解决，并发请求需建立多个连接（如浏览器默认 6 个 / 域名）。

#### （3）HTTP 2.0（2015）



- 核心更新：
    1. 二进制帧（Binary Frame）：将请求 / 响应拆分为二进制帧，而非文本格式，解析更快。
    2. 多路复用（Multiplexing）：同一连接下多个流（Stream）并行传输，无队头阻塞（一个流的帧丢失不影响其他流）。
    3. 头部压缩（HPACK）：压缩请求头（如 Cookie、User-Agent），减少传输量。
    4. 服务器推送（Server Push）：服务器主动推送资源（如 HTML 依赖的 CSS/JS），减少请求次数。
- 缺点：基于 TCP，仍存在 “TCP 层队头阻塞”（一个数据包丢失会阻塞整个连接）。

#### （4）HTTP 3.0（2022）



- 核心更新：
    1. 基于 QUIC 协议（UDP 之上）：解决 TCP 层队头阻塞，支持快速握手、连接迁移。
    2. 其他特性：继承 HTTP 2.0 的多路复用、头部压缩，进一步提升性能和可靠性。
- 优势：弱网环境下表现更好（如移动网络），连接建立更快，抗丢包能力更强。

### 15. MySQL 读写分离和主从复制



#### （1）读写分离核心



- 架构：部署一个主库（Master）和多个从库（Slave），主库负责写入（INSERT/UPDATE/DELETE），从库负责读取（SELECT），通过中间件（如 MyCat、Sharding-JDBC）路由请求。
- 目的：分散主库读写压力，提升查询吞吐量（读多写少场景如电商商品查询）。

#### （2）主从复制原理（基于 binlog）



1. 主库：写入操作完成后，将 SQL 语句记录到 binlog（二进制日志）。
2. 从库：
    - 开启 IO 线程：连接主库，读取主库的 binlog，写入本地的 relay log（中继日志）。
    - 开启 SQL 线程：读取 relay log，执行其中的 SQL 语句，同步主库数据。
3. 复制模式：
    - 异步复制（默认）：主库写入 binlog 后立即返回，不等待从库同步，可能存在数据延迟。
    - 半同步复制：主库写入 binlog 后，等待至少一个从库确认接收 relay log 后再返回，减少数据丢失风险。

#### （3）关键问题：数据延迟



- 解决方案：
    1. 核心业务（如支付）强制读主库。
    2. 从库开启并行复制（`slave_parallel_workers > 1`），提升同步速度。
    3. 合理拆分表，减少大事务（大事务会导致 binlog 过大，同步延迟）。

### 16. Redis 五大数据结构底层，点赞怎么实现？有没有更好的中间件？



#### （1）Redis 五大数据结构底层（JDK 8+）



| 数据结构 | 底层实现                                      | 核心特性                                                   |
| -------- | --------------------------------------------- | ---------------------------------------------------------- |
| String   | SDS（简单动态字符串）                         | 二进制安全、O (1) 长度获取、空间预分配                     |
| Hash     | 压缩列表（ZipList）→ 哈希表（HashTable）      | 小数据用 ZipList 省内存，大数据用 HashTable 提升查询效率   |
| List     | 压缩列表（ZipList）→ 双向链表（LinkedList）   | 小数据用 ZipList，大数据用 LinkedList                      |
| Set      | 整数集合（IntSet）→ 哈希表                    | 整数元素用 IntSet 省内存，其他用哈希表                     |
| ZSet     | 压缩列表（ZipList）→ 跳表（SkipList）+ 哈希表 | 小数据用 ZipList，大数据用跳表（排序）+ 哈希表（快速查询） |

#### （2）点赞实现方案



- 核心需求：点赞、取消点赞、查询点赞数、查询用户是否点赞、查询点赞列表。
- 实现方案：
    1. 点赞 / 取消点赞：用 `Set`（如 `zadd like:article:1001 user_id 时间戳`），`zadd` 点赞，`zrem` 取消点赞。
    2. 查询点赞数：`zcard like:article:1001`。
    3. 查询用户是否点赞：`zscore like:article:1001 user_id`（存在则已点赞）。
    4. 查询点赞列表（按时间排序）：`zrange like:article:1001 0 -1 withscores`。
- 优化：海量点赞场景（如千万级用户点赞），用 `HyperLogLog` 统计点赞数（牺牲精准度换内存）。

#### （3）更好的中间件？



- 若仅需点赞功能：Redis 足够（性能高、部署简单），无需额外中间件。

- 复杂场景（如社交互动：点赞、评论、关注）：可使用

  RocketMQ（消息队列）+ Elasticsearch（全文检索）

  组合：

    - RocketMQ 异步处理点赞事件（如点赞后发送消息，异步更新数据库和缓存）。
    - Elasticsearch 存储点赞列表，支持复杂查询（如按点赞时间、用户等级筛选）。

- 其他备选：MongoDB（文档型数据库，适合存储非结构化的互动数据）。

### 17. 看过哪些框架的源码？AOP 怎么实现的？



#### （1）框架源码推荐（面试高频）



- Spring 源码：核心是 IoC 容器（BeanFactory）和 AOP，重点看 `AbstractApplicationContext`（容器初始化）、`JdkDynamicAopProxy`（动态代理）。
- MyBatis 源码：核心是 SQL 解析、动态代理（Mapper 接口代理），重点看 `SqlSessionFactory`、`MapperProxy`。
- Redis 源码：核心是事件循环、数据结构（如跳表），重点看 `ae.c`（事件循环）、`skiplist.c`（跳表）。

#### （2）AOP 实现原理（Spring AOP 为例）



AOP（面向切面编程）核心是 “在不修改目标代码的前提下，动态增强方法功能”，Spring AOP 基于 **动态代理** 实现：

1. 核心概念

   ：

    - 切面（Aspect）：封装增强逻辑的类（如日志切面、事务切面）。
    - 连接点（JoinPoint）：可被增强的方法（如 service 层方法）。
    - 切入点（Pointcut）：筛选连接点的规则（如 `execution(* com.example.service.*.*(..))`）。
    - 通知（Advice）：增强逻辑（如前置通知 `@Before`、后置通知 `@AfterReturning`）。

2. 实现流程

   ：

    - 步骤 1：Spring 容器初始化时，扫描所有切面类（`@Aspect`），解析切入点和通知。
    - 步骤 2：对符合切入点规则的目标类，创建动态代理对象（JDK 动态代理或 CGLIB 动态代理）。
        - JDK 动态代理：目标类实现接口时使用，基于 `java.lang.reflect.Proxy`，代理类实现目标接口。
        - CGLIB 动态代理：目标类无接口时使用，基于字节码生成（ASM 框架），代理类继承目标类。
    - 步骤 3：调用目标方法时，先执行代理类的增强逻辑（通知），再执行目标方法。

3. 核心组件

   ：

    - `Advisor`：封装切入点和通知（如 `PointcutAdvisor`）。
    - `AopProxy`：动态代理接口，实现类 `JdkDynamicAopProxy`（JDK 代理）和 `CglibAopProxy`（CGLIB 代理）。
    - `ProxyFactory`：创建代理对象的工厂类。

### 18. 手写单例模式（双重检查锁定 DCL 模式，线程安全）



java

运行

```
public class Singleton {
    // volatile 关键字：禁止指令重排序，避免拿到未初始化的对象
    private static volatile Singleton instance;

    // 私有构造方法：禁止外部实例化
    private Singleton() {}

    // 双重检查锁定：懒加载 + 线程安全
    public static Singleton getInstance() {
        // 第一次检查：避免不必要的同步（提高效率）
        if (instance == null) {
            // 同步块：保证只有一个线程进入初始化逻辑
            synchronized (Singleton.class) {
                // 第二次检查：避免多个线程等待同步块后重复初始化
                if (instance == null) {
                    instance = new Singleton(); // 禁止重排序
                }
            }
        }
        return instance;
    }
}
```



- 关键：`volatile` 关键字必须加，否则 `instance = new Singleton()` 可能被拆分为 “分配内存→初始化对象→赋值引用” 的重排序，导致其他线程拿到未初始化的对象。

### 19. 算法题：两数之和



#### 题目要求：给定一个整数数组 `nums` 和一个目标值 `target`，找出数组中和为目标值的两个整数的索引。



#### 核心思路：哈希表（HashMap），时间复杂度 O (n)，空间复杂度 O (n)。



java

运行

```
import java.util.HashMap;
import java.util.Map;

public int[] twoSum(int[] nums, int target) {
    // 哈希表存储：key=数组元素值，value=元素索引
    Map<Integer, Integer> map = new HashMap<>();
    for (int i = 0; i < nums.length; i++) {
        int complement = target - nums[i];
        // 若互补值存在于哈希表，直接返回索引
        if (map.containsKey(complement)) {
            return new int[]{map.get(complement), i};
        }
        // 否则将当前元素存入哈希表
        map.put(nums[i], i);
    }
    // 题目假设一定有解，无需处理无结果情况
    throw new IllegalArgumentException("No two sum solution");
}
```
