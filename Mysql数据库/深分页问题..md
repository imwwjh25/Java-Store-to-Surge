数据库查询的**深分页问题**（如 `LIMIT 100000, 20`），核心痛点是：传统 `LIMIT offset, size` 会先扫描前 `offset+size` 条数据，再丢弃前 `offset` 条，扫描成本随 `offset` 增大线性增长，导致查询耗时暴增。

优化的核心思路是：**避免全量扫描，通过「定位起始位置」替代「偏移量跳过」**，结合索引、数据结构设计，将查询复杂度从 O (n) 降至 O (log n) 或 O (1)。

以下是 5 种落地性极强的优化方案（按优先级排序，覆盖不同场景）：

### 一、优先方案：游标分页（滚动分页）—— 无性能衰减



#### 核心原理



用「有序唯一的字段（如主键 ID、创建时间戳）」作为「游标」，通过 `WHERE 条件` 直接定位数据起始位置，替代 `offset`，避免扫描前 N 条数据。

#### 关键前提



排序字段必须是「唯一且有序」的（如自增主键 ID、`create_time + id` 组合，防止排序冲突）。

#### 实现步骤



1. 前端传递参数：`last_cursor`（上一页最后一条数据的游标值，首次查询传 `null`）+ `page_size`（每页条数）；

2. 后端 SQL 逻辑：
   ```
   -- 首次查询（last_cursor = null）：取前 20 条
   SELECT id, name, age FROM t_user ORDER BY id ASC LIMIT 20;
   
   -- 后续查询（last_cursor = 100020）：取 ID > 100020 的下 20 条
   SELECT id, name, age FROM t_user WHERE id > #{last_cursor} ORDER BY id ASC LIMIT #{page_size};
   ```



3. 前端渲染：每次请求后，记录返回结果中「最后一条数据的游标值」，作为下一页的 `last_cursor`。

#### 优点



- 性能极致：依赖索引（如 `id` 主键索引），查询时间复杂度 O (log n)，百万 / 亿级数据无性能衰减；
- 无数据遗漏 / 重复：即使数据新增 / 删除，基于游标定位也不会漏查或重复查（优于 `offset` 分页）。

#### 缺点



- 不支持「跳页查询」（如直接跳转到第 1000 页），仅支持「上一页 / 下一页」滚动；
- 排序字段固定（需提前约定，如按 ID 或创建时间排序）。

#### 适用场景



无限滚动列表（如电商商品列表、信息流、订单记录）、高并发查询场景。

### 二、兼容方案：覆盖索引 + 子查询 —— 支持跳页，改动小



#### 核心原理



若业务必须支持跳页（如管理后台分页），通过「覆盖索引」减少扫描数据量：先通过覆盖索引快速定位目标数据的主键 ID，再关联原表查询完整数据（避免全表扫描 + 回表）。

#### 关键前提



建立「排序字段 + 查询字段」的联合覆盖索引，确保子查询无需回表。

#### 实现步骤



1. 建立覆盖索引（以查询```id, name, age```、按```id```排序为例）：
   ```
   CREATE INDEX idx_id_name_age ON t_user (id, name, age); -- 覆盖查询字段，无需回表
   ```



2. 优化 SQL（对比传统分页）：

   sql

   ```
   -- 传统分页（慢：扫描前 100020 条数据，回表 100020 次）
   SELECT id, name, age FROM t_user ORDER BY id LIMIT 100000, 20;
   
   -- 优化后（快：子查询仅扫描索引，回表仅 20 次）
   SELECT t.id, t.name, t.age 
   FROM t_user t
   JOIN (
     -- 子查询：仅扫描覆盖索引，快速获取目标 ID（无回表）
     SELECT id FROM t_user ORDER BY id LIMIT 100000, 20
   ) tmp ON t.id = tmp.id;
   ```



#### 优点



- 支持跳页查询，前端无需改动（仍用 `pageNum + pageSize`）；
- 改动成本低，仅需优化 SQL + 建立覆盖索引。

#### 缺点



- 偏移量极端大时（如 `offset=100 万`）仍有性能损耗（但比传统分页快 10~100 倍）；
- 索引维护成本增加（新增 / 更新数据时需同步维护索引）。

#### 适用场景



管理后台、数据导出等必须跳页的场景，数据量不超过千万级。

### 三、进阶方案：预计算分块 —— 亿级数据支持跳页



#### 核心原理



提前将数据按「固定分块大小」预计算，存储分块信息（如每 1000 条为一个块，记录块的起始 / 结束 ID），查询时先定位块，再在块内小范围分页，避免大偏移量扫描。

#### 实现步骤



1. 建立分块表（存储分块元信息）：



   ```
   CREATE TABLE t_user_chunk (
     chunk_id INT PRIMARY KEY AUTO_INCREMENT, -- 块 ID（有序）
     start_id BIGINT NOT NULL, -- 块内起始 ID
     end_id BIGINT NOT NULL, -- 块内结束 ID
     chunk_size INT NOT NULL, -- 块内数据条数（如 1000）
     UNIQUE KEY idx_start_end (start_id, end_id)
   );
   ```



2. 预填充分块数据（通过定时任务更新）：

    - 按排序字段（如 `id`）批量扫描数据，每 1000 条数据生成一个块；

    - 示例分块数据：

      | chunk_id | start_id | end_id  | chunk_size |
           | -------- | -------- | ------- | ---------- |
      | 1        | 1        | 1000    | 1000       |
      | 2        | 1001     | 2000    | 1000       |
      | ...      | ...      | ...     | ...        |
      | 1000     | 999001   | 1000000 | 1000       |

3. 分页查询逻辑：

    - 输入参数：`pageNum=5001`，`pageSize=20`（查询第 5001 页，每页 20 条）；

    - 计算块 ID：`chunk_id = CEIL((pageNum - 1) * pageSize / chunk_size) = CEIL(5000*20/1000) = 100`；

    - 查分块表：获取 `start_id=99001`，`end_id=100000`；

    - 计算块内偏移量：`inner_offset = (pageNum - 1)*pageSize % chunk_size = 5000*20 % 1000 = 0`；

    - 最终 SQL：


      ```
      SELECT id, name, age FROM t_user 
      WHERE id BETWEEN 99001 AND 100000 
      ORDER BY id LIMIT 0, 20;
      ```



#### 优点



- 支持跳页，亿级数据下性能稳定（块内偏移量最大 999，扫描成本极低）；
- 分块表体积小（亿级数据仅 10 万条分块记录），查询速度快。

#### 缺点



- 需维护分块表（通过定时任务更新，适合静态 / 低频更新的数据）；
- 新增数据可能暂未分块（需定时任务补全，可接受短期延迟）。

#### 适用场景



亿级数据的分页查询（如历史订单、数据仓库）、必须支持跳页的场景。

### 四、兜底方案：限制最大页码 + 引导筛选



#### 核心原理



从业务层面规避深分页，引导用户通过筛选条件缩小查询范围，而非无限制跳页。

#### 实现方式



1. 限制最大页码：前端禁止用户跳转到超过 `1000` 页（可配置），超过则提示 “请通过筛选条件缩小范围”；
2. 强化筛选功能：提供时间范围（如近 7 天、近 30 天）、分类、状态等筛选条件，用户筛选后数据量减少，`offset` 自然变小；
3. 异步导出：对于 “导出全部数据” 等场景，不使用分页查询，而是通过异步任务生成 CSV 文件，用户下载（避免实时查询压力）。

#### 优点



- 零技术改动，完全从业务层面解决；
- 减少无效查询（如用户恶意跳转到 10 万页），降低数据库压力。

#### 缺点



- 影响用户体验（限制跳页），需产品层面配合。

#### 适用场景



所有场景的兜底方案，尤其适合管理后台、低并发场景。

### 五、特殊场景：Elasticsearch 深分页优化



若数据已同步到 Elasticsearch（ES），深分页问题可通过 ES 专属机制优化（ES 原生不支持大 `from` 偏移量）：

1. **Scroll API**：类似游标分页，生成一个滚动 ID（scroll_id），每次通过 scroll_id 获取下一批数据，支持亿级数据遍历（不支持跳页）；
2. **Search After**：基于上一页最后一条数据的排序字段值（如 `id:100020`），查询下一页数据（支持滚动，不支持跳页）；
3. **Index Alias + 时间分片**：按时间分索引（如 `user_202511`、`user_202512`），查询时仅扫描目标时间范围的索引，减少数据量。

### 优化方案选择决策树




```plaintext
是否支持跳页？
├─ 否 → 游标分页（优先）
├─ 是 → 数据量是否超过千万级？
   ├─ 否 → 覆盖索引 + 子查询（改动小）
   ├─ 是 → 预计算分块（亿级稳定）
是否允许业务限制？
├─ 是 → 限制最大页码 + 引导筛选（兜底）
数据是否在 ES 中？
├─ 是 → Scroll API / Search After（ES 专属）
```



### 关键优化细节



1. 索引必须生效：所有优化方案的核心是「排序字段 + 查询条件」命中索引，避免全表扫描（如游标分页的 `id` 需为主键索引，覆盖索引需包含所有查询字段）；
2. 避免回表：尽量通过覆盖索引直接返回结果，减少 `SELECT *`（仅查询需要的字段）；
3. 并行查询：分库分表场景下，可按库表并行执行查询（如预计算分块时，100 个库同时扫描），提升效率；
4. 监控告警：对大偏移量查询（如 `offset>10 万`）添加监控告警，及时发现慢查询并优化。

通过以上方案，可彻底解决深分页导致的慢查询问题，兼顾性能、业务灵活性和落地成本。