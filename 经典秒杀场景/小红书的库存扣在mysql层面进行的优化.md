## 出自


小红书微信公众号：小红书技术REDtech - 2026/1/19那篇文章



## 秒杀场景的性能瓶颈的根源


我们从经典的库存扣减的事务模型出发：


```sql
begin;
insert into inventory_log value (...); -- 流水插入（无冲突）
update inventory set quantity=quantity-1 where sku_id=? and quantity > 0; -- 热点行更新（冲突核心）
commit;
```

**并发瓶颈本质**：

1. **行锁竞争**：所有事务争抢热点行（`sku_id`）的排他锁，同一时间仅一个事务能持有锁，其余事务阻塞等待，导致 TPS 随并发数升高急剧下降。
2. **事务粒度大**：每个事务独立执行`insert+update+commit`，即使`insert`无冲突，也需等待`update`锁释放，整体吞吐受限于单锁性能。
3. **线程切换开销**：高并发下大量线程阻塞 / 唤醒，CPU 资源浪费在上下文切换，而非有效计算。



## 合并秒杀方案核心原理


方案本质是 **「将多个独立事务的热点行更新合并为一个批量更新，减少锁持有时间和事务提交次数」**，核心流程基于 **Leader-Follower 协作模型 + 全局缓存**：

### 1. 核心流程（以 1 个 Leader+2 个 Follower 扣减 3 次库存为例）

|               阶段               |                           操作细节                           |
| :------------------------------: | :----------------------------------------------------------: |
|      **1. 抢占 Leader 锁**       | 多个线程争抢热点行的**独占锁**，抢到的线程标记为`Leader`，其余为`Follower`。 |
|     **2. Leader 预加载数据**     | Leader 读取 InnoDB 中热点行的当前库存（如`quantity=1000`），写入**全局缓存**（表维度共享，解决多线程数据可见性问题）。 |
|   **3. Follower 缓存合并扣减**   | Leader 释放独占锁，Follower 依次抢占锁：① 读取全局缓存的库存值；② 在线程缓存中完成扣减（如`1000→999→998`）；③ 将扣减后的值写回全局缓存；④ 释放锁，进入等待唤醒状态。 |
|      **4. Leader 批量提交**      | Leader 等待预设时间（收集足够多的 Follower 事务），重新抢占独占锁，将全局缓存的最终扣减值（如`998`）批量更新到 InnoDB，并提交事务。 |
| **5. 唤醒 Follower+Binlog 同步** | Leader 提交成功后，唤醒所有 Follower；**Binlog 并行提交**：Leader 统一生成批量更新的 Binlog（格式与原生一致，兼容 Canal/DTS 等组件），保证生态无感知。 |

### 2. 关键技术点

#### （1）全局缓存：解决多线程数据可见性

- **设计**：按**表维度**维护全局缓存，所有操作同一张表热点行的线程共享该缓存，缓存生命周期与表结构绑定，便于管理。
- **作用**：替代传统的「线程私有数据」，让 Follower 能基于 Leader 的初始数据进行增量扣减，无需每次访问数据库。

#### （2）Leader-Follower 协作：拆分锁阶段

- 锁阶段拆分：将传统的「更新 + 提交」单锁阶段，拆分为

  「缓存收集阶段」和「批量提交阶段」：

    - 缓存收集阶段：锁持有时间极短（仅用于读写缓存）；
    - 批量提交阶段：仅 Leader 持有锁完成最终更新，减少锁竞争时间。



- **流水线优化**：**前一组提交时，后一组可并行收集**（如第一组提交`998`时，第二组已开始从`998`扣减），进一步压缩整体耗时。

#### （3）事务模型修改：兼容原生 MySQL

- 内核层修改**事务提交逻辑**，但**不修改 InnoDB 存储格式**，保证版本兼容性和回退能力；
- 输出的 Binlog 与原生一致（记录每个事务的独立改动，如`1000→999、999→998`），而非批量改动，确保下游同步工具无感知。

## Crash Recovery：异常场景的一致性保障


合并秒杀修改了事务模型，**最大挑战是宕机后的恢复一致性**（Redolog 记录批量改动，Binlog 记录单个事务改动），解决方案是 **「组粒度的提交 / 回滚」**：

1. **Redolog 记录**：Leader 提交时，Redolog 记录**组级别的最终改动**（如`1000→998`）。

2. **Binlog 记录**：Binlog 记录**组内每个事务的独立改动**（如`1000→999、999→998`）。

3. 恢复逻辑 ：宕机后，以事务组为单位对比 Redolog 和 Binlog：

    - 若 Binlog 组完整（所有事务都记录），则按 Redolog 提交最终数据；
    - 若 Binlog 组不完整，则回滚整个组的改动，保证数据一致性。


## 问题1


```text

如果此时库存为 2，而此时有很多用户在参与秒杀，所以会将多个事务合并为一个，假设 queue 中有 n (n > 2) 个扣减库存事务，合并后的 sql 为 quantity - n, 扣减完后 quantity 为负，显然会失败。
那么假设为很热门的秒杀商品，服务端源源不断地涌来新的秒杀请求，每个 group 都很快地被填满，在极端情况下是否库存会一直扣减失败

```


### 一、合并秒杀的核心机制：库存扣减的安全边界

合并秒杀方案并非简单地将 `n` 个请求合并为 `quantity = quantity - n`，而是在**缓存阶段就做了库存校验**，避免出现你担心的批量扣减后库存为负的情况。

1. **全局缓存的实时校验**



- Leader 预加载库存到全局缓存后，每个 Follower 线程在扣减时，都会先检查缓存中的剩余库存是否足够（如当前缓存库存为 `2`，第 3 个 Follower 请求扣减时会发现 `2-1 < 0`，直接在缓存阶段拒绝该请求）。
- 这意味着，最终合并提交到数据库的扣减值，一定是**不超过当前库存的安全值**（例如最多只合并 2 个有效请求，扣减后库存为 0），不会出现批量扣减导致负数的情况。



2. **数据库层的最终兜底校验**



- 即使缓存校验出现极端异常，最终提交到数据库的```UPDATE```语句依然保留了```WHERE quantity > 0```的条件：

```
     UPDATE inventory SET quantity = quantity - m WHERE sku_id = ? AND quantity >= m;
```



- 这里的 `m` 是缓存阶段校验后的有效扣减数量（`m ≤ 库存当前值`），因此数据库层会再次保证扣减不会让库存为负。



------

### 二、极端场景下的库存防护：不会出现 “一直扣减失败”

在 “请求源源不断、Group 快速填满” 的极端场景下，方案通过以下机制保证库存扣减的稳定性：

1. **动态 Group 大小与超时控制**



- 合并秒杀的 Group 不是无限制等待填满，而是有**超时时间**（例如 10ms）和**最大合并数量**（例如 100 个请求）。
- 即使请求持续涌入，到了超时时间或达到最大数量，Leader 就会立即提交当前 Group 的有效请求（即缓存校验通过的 `m` 个请求），不会无限等待。
- 这确保了库存扣减是**批次化、周期性推进**的，不会因后续请求而阻塞当前批次的提交。



2. **缓存与数据库的实时同步**



- 每个 Group 提交后，Leader 会立即更新全局缓存的库存值（例如从 `2` 变为 `0`）。
- 后续新到来的请求在缓存阶段会直接发现库存为 0，无需进入 Group 排队，直接返回 “秒杀失败”，避免无效请求占用资源。



3. **流量削峰与熔断机制**



- 业务层通常会配合**流量控制**（如令牌桶、漏桶算法），限制单位时间内的请求量，避免数据库层被压垮。
- 当库存耗尽后，服务端会快速返回 “商品已售罄”，不会让无效请求持续进入数据库，从根源上避免 “一直扣减失败” 的情况。



------

### 三、实际业务中的兜底保障

在真实的秒杀场景中，除了数据库层的机制，业务侧还会做多层防护：

- **库存预占**：在 Redis 中提前预占库存，请求先经过 Redis 校验，只有预占成功的请求才会进入数据库扣减，大幅减少无效请求。
- **库存水位监控**：实时监控库存剩余量，当库存接近 0 时，动态调整合并秒杀的 Group 大小（如减小批量），提升扣减成功率。
- **降级开关**：当出现异常时，可快速切换回 “排队秒杀” 或 “普通更新” 模式，避免单一方案的风险。

------

### 结论

合并秒杀方案通过**缓存阶段的实时校验**、**数据库层的最终兜底**和**动态 Group 的批次提交**，不会出现 “库存一直扣减失败” 的情况。即使在极端高并发下，库存扣减也会稳定推进，直到库存耗尽后快速拒绝后续请求。



## 问题2

```text
合并秒杀方案如何保证 ACID 中的隔离性
```


## 一、基于「组粒度」的事务隔离

合并秒杀将多个请求合并为一个事务组提交，但在**缓存计算阶段**和**最终提交阶段**都做了隔离性防护：

1. **全局缓存的线程隔离**



- 每个事务组（Group）拥有独立的全局缓存副本，不同 Group 的缓存数据相互隔离。
- Follower 线程仅能读取当前 Group 的缓存，无法访问其他 Group 的中间状态，避免了跨 Group 的脏读。
- 例如：Group A 正在扣减库存从`1000→998`，Group B 只能基于`998`开始计算，不会读取到 Group A 的中间值（如`999`）。



2. **Leader 的独占锁机制**



- 每个事务组的 Leader 会抢占热点行的**独占锁**，在锁持有期间，其他事务组无法修改该行数据。
- 这保证了同一时间只有一个 Group 能对热点行进行批量更新，不同 Group 之间完全串行，避免了并发更新导致的不可重复读。



------

## 二、缓存与数据库的一致性隔离

1. **缓存阶段的版本校验**



- Leader 预加载库存时，会记录当前数据的**版本号（或事务 ID）**，Follower 在扣减缓存时会校验版本号。
- 如果发现缓存版本与数据库版本不一致（如其他事务已修改数据），则当前 Group 会自动降级为排队秒杀，避免脏数据进入缓存。



2. **2PC 提交的原子性隔离**



- Leader 在批量提交时，采用

  两阶段提交（2PC）：

    1. **准备阶段**：将全局缓存的最终扣减值写入 Redolog，锁定热点行；
    2. **提交阶段**：提交 Binlog 并释放行锁。



- 整个过程中，其他事务无法读取到未提交的中间状态，避免了脏读；同时，只有当整个 Group 的事务都提交成功，才会释放锁，保证了事务的原子性与隔离性。



------

## 三、与原生 MySQL 隔离级别的兼容

合并秒杀方案**完全兼容 MySQL 的隔离级别**（如可重复读、读已提交），核心是通过内核层的改造，让合并后的事务组表现为「单个大事务」：

- 在 ** 可重复读（RR）** 隔离级别下，每个事务组的 Follower 线程基于全局缓存计算，缓存数据是 Leader 预加载的快照，不会读取到其他事务的未提交修改。
- 在 ** 读已提交（RC）** 隔离级别下，Leader 提交后立即更新全局缓存，后续事务组会读取到最新的已提交数据，符合隔离级别的要求。

------

## 四、异常场景下的隔离性保障

1. **Crash Recovery 的组粒度回滚**



- 若宕机时事务组未完全提交，恢复过程会以**组为单位**回滚所有未提交的事务，不会出现部分事务提交、部分回滚的情况，保证了隔离性。



2. **动态降级的隔离兼容**



- 当合并秒杀触发降级（如缓存校验失败）时，会自动切换为排队秒杀或普通更新模式，这些模式完全遵循原生 MySQL 的隔离机制，不会破坏整体隔离性。



------

## 总结

合并秒杀方案通过**组粒度的锁机制、缓存版本校验、2PC 提交**，在提升性能的同时，严格保证了事务的隔离性，完全符合 ACID 原则。它的核心思路是：**将多个小事务合并为一个大事务组，通过内核层的改造，让这个大事务组表现得像原生 MySQL 事务一样，既满足隔离性要求，又提升了并发性能**。



# 思考


1. 首先就是还是优化的通用方法中比较常见的思考就是**分批或者批量**，将一个大事务或者大的行锁持有时间拆分成为不同的小的部分，目的是针对核心的操作进行快速响应，然后在异步的保证各项要求，如缓存一致性等
