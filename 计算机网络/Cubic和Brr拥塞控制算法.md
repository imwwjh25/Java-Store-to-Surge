
## 一、背景：为什么需要拥塞控制算法？

TCP 协议的核心目标是 **可靠传输 + 高效利用网络带宽**，但网络带宽、延迟是动态变化的，且存在 “带宽竞争”（多个连接共享链路）。如果发送方盲目提速，会导致：

- 网络拥塞（数据包排队、丢失）；
- 重传风暴（大量丢失包重传，进一步加剧拥塞）；
- 带宽利用率低下（过度保守导致资源浪费）。

拥塞控制算法的核心作用：**通过感知网络状态（延迟、丢包、带宽），动态调整发送方的 “发送速率” 或 “拥塞窗口（cwnd）”**，在 “避免拥塞” 和 “最大化带宽利用率” 之间找到平衡。

传统经典算法（如 Reno、CUBIC 的前身 BIC）主要基于 “丢包” 作为拥塞信号，但存在明显缺陷（下文会对比）。而 BBR 是 Google 提出的 “基于带宽和延迟” 的新型算法，彻底改变了拥塞控制的思路。

## 二、CUBIC 算法：基于丢包的改进型拥塞控制

CUBIC 是 Linux 内核默认的 TCP 拥塞控制算法（2.6.24+），是对 BIC 算法的优化，核心设计目标是：**在高速网络（如数据中心、长肥管道 WAN）中，兼顾公平性和高带宽利用率，减少 RTT 不公平性**。

### 1. 核心设计思想

CUBIC 基于 “丢包触发拥塞窗口调整”，但解决了传统 Reno 算法的两个关键问题：

- Reno 算法在拥塞避免阶段采用 “线性增长”（cwnd += 1/cwnd 每 RTT），高速网络下增长过慢，带宽利用率低；
- Reno 对 RTT 敏感（短 RTT 连接会抢占更多带宽），公平性差。

CUBIC 的核心创新：**拥塞窗口的增长 / 下降遵循 “三次函数曲线”**，而非线性或指数，使得：

- 远离拥塞点时，窗口增长快速（抢占带宽）；
- 接近拥塞点时，窗口增长放缓（避免触发拥塞）；
- 对不同 RTT 的连接公平性更好（长 RTT 连接也能获得合理带宽）。

### 2. 关键阶段与机制

CUBIC 的生命周期分为 4 个阶段，与 Reno 算法兼容，但核心逻辑在 “拥塞避免” 阶段：

#### （1）慢启动阶段（Slow Start）

- 触发条件：连接建立初期，或拥塞后恢复（丢包后窗口重置为 1）；
- 机制：拥塞窗口（cwnd）**指数增长**（每 RTT 翻倍），直到达到 “慢启动阈值（ssthresh）”；
- 目的：快速探索网络可用带宽，避免初期传输过慢。

#### （2）拥塞避免阶段（Congestion Avoidance）

- 触发条件：cwnd 达到 ssthresh 后进入；

- 核心机制：cwnd 随时间按 “三次函数” 增长，公式如下：







  ```plaintext
  cwnd(t) = C*(t - K)^3 + W_max
  ```



- `C`：三次函数系数（控制增长速率，默认值优化后平衡速度与稳定性）；
- `t`：当前时间（从上次拥塞点开始计算）；
- `K`：窗口增长到 W_max 所需的时间（K = (W_max / C)^(1/3)）；
- `W_max`：上一次拥塞时的窗口大小（丢包前的峰值）；

- 过程解析：

    1. 丢包后，W_max 记录为当前 cwnd，然后 cwnd 下降到 W_max * β（β 是下降系数，默认 0.7）；
    2. 恢复阶段，t 从 0 开始增长，cwnd 按三次函数从 W_max*β 逐步回升；
    3. 当 cwnd 接近 W_max 时，(t-K)^3 趋近于 0，增长速度放缓，避免再次触发丢包；

- 优势：相比 Reno 的线性增长，CUBIC 在远离 W_max 时增长更快（如 W_max=1000，β=0.7，初期每 RTT 可增长几十），高速网络下带宽利用率更高。

#### （3）快速重传 / 快速恢复阶段（Fast Retransmit/Fast Recovery）

- 触发条件：收到 3 个重复 ACK（表示数据包丢失，但网络未完全拥塞）；
- 机制：
    1. 快速重传丢失的数据包；
    2. ssthresh 调整为 cwnd/2，cwnd 调整为 ssthresh + 3（ Reno 逻辑）；
    3. 之后每收到一个重复 ACK，cwnd += 1；
    4. 收到新的 ACK 后，退出快速恢复，进入拥塞避免阶段；
- 目的：在不触发全局拥塞的情况下，快速恢复丢失的数据包，减少重传延迟。

#### （4）超时重传阶段（Timeout Recovery）

- 触发条件：未收到 ACK 且超时（表示网络严重拥塞）；
- 机制：
    1. ssthresh 调整为 cwnd/2；
    2. cwnd 重置为 1；
    3. 重新进入慢启动阶段；
- 目的：彻底降低发送速率，缓解网络拥塞。

### 3. 核心优势与缺陷

#### 优势：

- 高速网络适配性好：三次函数增长在大带宽场景下，带宽利用率远高于 Reno；
- 公平性优：对不同 RTT 的连接公平性更好（长 RTT 连接不会被短 RTT 连接完全抢占）；
- 兼容性强：与 Reno 算法的慢启动、快速重传逻辑兼容，部署成本低。

#### 缺陷：

- 依赖丢包作为拥塞信号：只有当数据包丢失时才调整窗口，存在 “滞后性”；
- 不适合高延迟 / 高丢包网络：在卫星通信、移动网络等场景中，丢包可能是链路错误而非拥塞，导致窗口误调（过度保守）；
- 带宽利用率仍有上限：受限于 “丢包触发”，无法主动感知网络的真实带宽上限。

## 三、BBR 算法：基于带宽和延迟的革命性算法

BBR（Bottleneck Bandwidth and RTT）是 Google 在 2016 年提出的拥塞控制算法，核心设计思想是 **“不依赖丢包，而是通过测量网络的真实带宽和延迟，动态调整发送速率”**，彻底颠覆了传统拥塞控制的逻辑。

### 1. 核心设计思想

BBR 的核心洞察：**网络的拥塞瓶颈由 “瓶颈带宽（Bottleneck Bandwidth）” 和 “最小 RTT（Min RTT）” 决定**。

- 瓶颈带宽：路径中最慢链路的带宽（如路由器、交换机的转发速率上限）；
- 最小 RTT：网络空载时的往返延迟（反映链路的物理延迟，无排队延迟）；
- 理想发送速率 = 瓶颈带宽 × 最小 RTT（即 “带宽延迟积 BDP”，表示网络链路能容纳的最大数据包数量）。

BBR 的目标：**让发送速率稳定在 “瓶颈带宽 × 最小 RTT” 附近**，既不浪费带宽，也不导致数据包排队（排队会增加 RTT）。

### 2. 核心机制：两个关键测量 + 四个状态机

#### （1）两个核心测量指标

BBR 算法的基础是准确测量以下两个指标：

1. 瓶颈带宽（Bw） ：

    - 测量方式：通过 “已确认数据量 / 确认时间” 计算（每 RTT 更新一次）；
    - 核心逻辑：只保留 “最大带宽样本”（因为瓶颈带宽是路径上限，不会突然增加，除非网络状态改善）；

2. 最小 RTT（Rtt） ：

    - 测量方式：记录所有 RTT 样本，保留最小值（Min RTT 反映链路物理延迟，排队延迟会导致 RTT 增大）；
    - 核心逻辑：定期（默认 10 秒）重新校准 Min RTT（避免因网络拓扑变化导致的误差）。

#### （2）四个状态机（生命周期）

BBR 算法通过四个状态机循环，动态调整发送速率，确保稳定在 BDP 附近：

| 状态                      | 触发条件                                   | 核心行为                                                     | 目的                                                         |
| ------------------------- | ------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **STARTUP（启动）**       | 连接建立初期，或拥塞后恢复                 | 发送速率按指数增长（每 RTT 翻倍），直到测量到的带宽不再增长（达到瓶颈） | 快速探索网络的瓶颈带宽，避免初期传输过慢                     |
| **DRAIN（排空）**         | STARTUP 阶段检测到带宽不再增长（达到瓶颈） | 停止速率增长，快速排空网络中因 STARTUP 阶段过度发送导致的排队数据包 | 减少排队延迟，让 RTT 回归到 Min RTT 附近                     |
| **PROBE_BW（带宽探测）**  | DRAIN 阶段结束（RTT 接近 Min RTT）         | 发送速率在 “瓶颈带宽 × Min RTT” 附近小幅度波动（周期性增加 25% 后回落） | 持续探测网络是否有额外带宽（如其他连接释放带宽），同时避免排队 |
| **PROBE_RTT（延迟探测）** | 每 10 秒触发一次，或 Min RTT 长时间未更新  | 发送速率降至最低（仅发送少量数据包），持续 200ms，重新测量 Min RTT | 校准 Min RTT（避免因网络拓扑变化导致的误差），确保速率计算准确 |

#### （3）关键优化：避免排队延迟

BBR 算法的核心优势之一是 “避免数据包排队”，其逻辑是：

- 当测量到的 RTT 大于 Min RTT × 1.25（默认阈值）时，认为网络开始排队；
- 此时立即降低发送速率，直到 RTT 回归到 Min RTT 附近；
- 相比 CUBIC 等依赖丢包的算法，BBR 能提前感知拥塞（排队延迟增加），而非等到数据包丢失。

### 3. 核心优势与缺陷

#### 优势：

- 不依赖丢包：在高延迟 / 低丢包（如卫星通信）、高丢包 / 低延迟（如移动网络）场景中，性能远超传统算法；
- 带宽利用率极高：稳定在 BDP 附近，几乎能占满瓶颈带宽；
- 低延迟：避免数据包排队，RTT 更稳定（对实时性要求高的场景如视频通话、游戏至关重要）；
- 公平性好：多个 BBR 连接共享带宽时，会根据各自的 BDP 分配资源，不会出现某一连接抢占全部带宽的情况。

#### 缺陷：

- 兼容性问题：与传统拥塞控制算法（如 Reno、CUBIC）共存时，BBR 可能会抢占更多带宽（因为 BBR 不依赖丢包，而传统算法会因丢包降低窗口）；
- 部署成本：需要内核支持（Linux 4.9+ 已集成，Windows、macOS 需手动配置）；
- 对测量误差敏感：如果 Min RTT 或瓶颈带宽测量不准确（如网络抖动剧烈），会导致发送速率波动。

## 四、CUBIC 与 BBR 核心对比

| 对比维度   | CUBIC                                | BBR                                             |
| ---------- | ------------------------------------ | ----------------------------------------------- |
| 拥塞信号   | 丢包（3 次重复 ACK 或超时）          | 带宽 + 延迟（Bottleneck Bandwidth + Min RTT）   |
| 核心逻辑   | 三次函数调整拥塞窗口（cwnd）         | 基于 BDP 调整发送速率（rate-based）             |
| 带宽利用率 | 中高（高速网络下优于 Reno）          | 极高（接近 BDP 上限）                           |
| 延迟表现   | 中等（依赖丢包，可能出现排队）       | 极低（避免排队，RTT 稳定）                      |
| 适用场景   | 有线网络、数据中心（低延迟、低丢包） | 移动网络、卫星通信、实时通信（高延迟 / 高丢包） |
| 兼容性     | 强（与 Reno 兼容）                   | 一般（与传统算法共存时公平性需优化）            |
| 内核支持   | Linux 2.6.24+（默认）                | Linux 4.9+（需手动启用）                        |
| 典型应用   | 常规 Web 服务、文件传输              | YouTube、Google Search、实时视频通话            |

## 五、面试常问延伸问题

### 1. 为什么 BBR 在移动网络中表现更好？

移动网络的特点是 “高丢包（链路波动）、低延迟”，传统算法（如 CUBIC）会将丢包误认为拥塞，从而降低发送窗口，导致带宽利用率极低。而 BBR 不依赖丢包，通过测量真实带宽和延迟调整速率，即使存在少量丢包，也能保持高带宽利用率，同时避免排队延迟。

### 2. CUBIC 如何解决 Reno 算法的 RTT 不公平性？

Reno 算法在拥塞避免阶段采用线性增长（cwnd += 1/cwnd 每 RTT），短 RTT 连接的 cwnd 增长更快（相同时间内经历更多 RTT），会抢占长 RTT 连接的带宽。而 CUBIC 的三次函数增长与 RTT 无关，只与时间相关（t 是绝对时间，而非 RTT 次数），因此长 RTT 连接和短 RTT 连接的窗口增长速率一致，公平性更好。

### 3. BBR 中的 “带宽延迟积（BDP）” 是什么？为什么重要？

BDP = 瓶颈带宽 × 最小 RTT，表示网络链路能容纳的最大数据包数量（即 “链路容量”）。例如：

- 瓶颈带宽 = 100 Mbps，最小 RTT = 10ms；
- BDP = (100 Mbps × 10ms) / 8 = 125 KB（每个数据包按 1KB 计算，可容纳 125 个数据包）。

BBR 基于 BDP 调整发送速率，确保发送的数据包数量不超过 BDP，从而避免数据包排队（排队会增加 RTT），同时最大化带宽利用率。如果发送速率超过 BDP，数据包会在瓶颈链路排队，导致延迟增加；如果低于 BDP，带宽会被浪费。

### 4. 如何在 Linux 中启用 BBR 算法？

步骤如下（需 Linux 4.9+ 内核）：






```bash
# 1. 检查内核版本
uname -r

# 2. 启用 BBR
echo "net.ipv4.tcp_congestion_control = bbr" >> /etc/sysctl.conf
echo "net.core.default_qdisc = fq" >> /etc/sysctl.conf

# 3. 生效配置
sysctl -p

# 4. 验证是否启用成功
sysctl net.ipv4.tcp_congestion_control  # 输出 bbr
lsmod | grep tcp_bbr                     # 输出 tcp_bbr 模块
```

### 5. 分布式系统中，如何选择 CUBIC 或 BBR？

- 选 CUBIC：如果系统部署在数据中心（低延迟、低丢包），且需要兼容传统客户端（如老版本浏览器、设备），CUBIC 是更稳妥的选择；
- 选 BBR：如果系统涉及移动网络（如 App 后端）、跨地域通信（如 CDN 分发）、实时性要求高（如视频会议、直播），BBR 能显著提升传输性能（降低延迟、提高带宽利用率）。

## 六、总结

- **CUBIC** 是基于丢包的经典算法，兼容传统场景，在高速有线网络中表现稳定，核心优势是公平性和兼容性；
- **BBR** 是基于带宽和延迟的革命性算法，不依赖丢包，在高延迟、高丢包场景中性能碾压传统算法，核心优势是低延迟和高带宽利用率；
- 面试中，需重点掌握两者的核心设计思想、区别及适用场景，同时理解 “拥塞控制的本质是平衡带宽利用率和延迟” 这一核心逻辑。
